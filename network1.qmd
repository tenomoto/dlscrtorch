# ニューラルネットワークを白紙から

この章では、回帰問題を解く。
とはいっても、`lm`ではない。
実際にニューラネルネットワークを構築が、テンソルだけを使う（言うまでもなく *autograd* を有効にしたもの）。
もちろん、今後このやり方で`torch`を使うわけではないが、無駄な努力にはならない。
むしろその逆だ。
基本的な仕組みを見ることで、`torch`が多くの手間を省いてくれることを認識できるだろう。
それに、基本を理解することは、驚くほどよくある、深層学習をある種の「魔法」と考えてしまう罠に対する有効な対策になる。
それは行列演算の繰り返しに過ぎない。
学ぶべきはこれらをまとめ上げることだ。

回帰を行うネットワークに必要なものから始めよう。

## ネットワークの考え方

簡単にいうと、ネットワークは入力から出力への関数だ。
適切な函数が求めるものだ。

これを決めるには、会期として線型回帰を考えてみよう。
線型回帰がしているのは、掛け算と足し算だ。
独立変数一つ一つに対して、これに掛ける係数がある。
それから、*バイアス* と呼ばれる項を末尾に加える。
（二次元では、回帰係数とバイアスは回帰直線の傾きとy切片である。）

これらを考慮すると、乗算と加算はテンソルでできることで、テンソルはこれらの演算のためにあると言ってもいいくらいだ。
例として、入力が百個の観測からなり、特徴量がそれぞれ三つあるものを示す。

```{r}
library(torch)

x <- torch_randn(100, 3)
x$size()
```

`x`に掛ける特徴量ごとの係数を格納するために、特徴量の数である長さ3の列ベクトルが必要だ。
あるいは、この後すぐ行う修正に備えて、列の長さが三の行列にしてもよい。
つまり、三行を持つ行列である。
列はいくつ必要か。
単一の特徴量を予測したいとすれば、行列は大きさ3 x 1となる。

よさそうな候補を乱数で初期化する。
テンソルは`requires_grad = TRUE`をつけて作成されていることに留意する。
この変数はネットワークに学習てもらいたいパラメタを表しているからだ。

```{r}
w <- torch_randn(3, 1, requires_grad = TRUE)
```

バイアステンソルは大きさ1 x 1となる。

```{r}
b <- torch_zeros(1, 1, requires_grad = TRUE)
```

これで、データに重み`w`をかけ、バイアス`b`を加えて「予測」を得ることができる。

```{r}
y <- x$matmul(w) + b
print(y, n = 10)
```

数学の表記では、ここでは次の函数を実装した。

$$
f(\mathbf{X}) = \mathbf{X}\mathbf{W} + \mathbf{b}
$$

これのどこがニューラルネットワークなのか。

## ネットワークの層

ニューラルネットワークの用語に戻れば、ここでしたのは単層のネットワーク、出力層の動作の原型である。
単層ネットワークは構築したい類とはとてもいえない。
単に線型内挿すれば済むのに、なぜネットワークを作るのか。
実際、ニューラルネットワークの特徴は、（理論的に）無数の層を連鎖できることになある。
もちろん出力層以外は「隠れ」層と呼ばれるが。深層学習フレームワークを使う上では全く *隠れ* ている訳ではない。

例えば、隠れ層が一つあるネットワークを作りたいとしよう。
その大きさ、つまり層が持つユニットの数はネットワークの力を決める重要な要因になる。
この数は作成する重み行列の大きさに反映される。
八つのユニットを持つ層には八つの列を持つ行列が必要である。

```r
w1 <- torch_randn(3, 8, requires_grad = TRUE)
```

各ユニットにはそれぞれバイアス値もある。

```r
b1 <- torch_zeros(1, 8, requires_grad = TRUE)
```

以前見たように、隠れ層は受け取った入力に重みを掛けてバイアスを加える。
つまり、上に示した函数$f$を適用する。
そして、別の函数を適用する。
この函数は隠れそうから入力を受け取り、最終出力を生成する。
結局、ここで行われているのは函数の合成である。
二番目の函数$g$を呼び出すと、全体の変換は$g(f(\mathbf{X}))$つまり$g\circ f$となる。


上述の単層構造に類似した出力を$g$がするには、その重み行列は八つの列の隠れ層を取り、単一の列にしなければならない。
つまり、`w2` は次のようになる。

```r
w2 <- torch_randn(8, 1, requires_grad = TRUE)
```

バイアス`b2`は`b1`のように単一の値である。

```r
b2 <- torch_randn(1, 1, requires_grad = TRUE)
```

もちろん、単一の隠れ層に止める理由はなく、仕組みを完成させたら、自由にコードをいじってほしい。
でも最初に、追加しなければならない部品がいくつかある。
その一つは、今の構造では函数を連鎖、あるいは合成しているのはよいが、これらの函数がしているのは加算と乗算であり、線型である。
しかし、ニューラルネットワークの力は通常 *非線型性* にある。なぜか。


## 活性化函数

ここで、三つの層からなるネットワークがあったとして、各層では入力に重みを掛けただけだとする。
（バイアス項を考慮することで変わるものはないにもないが、例がややこしくなるだけなので、省略する。）

このネットワークは行列積の連鎖 $f(\mathbf{X}) = ((\mathbf{XW}_1)\mathbf{W}_2)\mathbf{W}_3$ になる。
さて、この式を変形するとすべての重み行列を掛け合わせてから$\mathbf{X}$に作用させ$f(\mathbf{X}) = \mathbf{X}(\mathbf{W}_1\mathbf{W}_2\mathbf{W}_3)$と書くことができる。
つまり三つの層のネットワークは単層のものに簡略化され、$f(\mathbf{X}) = \mathbf{XW}_4$となる。
こうなると、深層ニューラルネットワークの利点がすべて失われてしまう。

ここで活性化函数、時に「非線型性」が登場する。
これは非線型演算を導入するもので、行列演算でモデル化することはできない。
歴史的には典型的な活性化函数は *シグモイド* であり、現在でも極めて重要である。
その本質的な作用は入力を0と1との間に圧縮して確率と解釈できる量を与える。
回帰では、これが求めるものではなく、ほとんどの隠れ層についても同様だ。

代わりに、ネットワークの中で最も利用されている活性化函数は *ReLU*、Rectified Linear Unit（正規化線型函数）と呼ばれるものだ。
名前は長いが単に全ての負の値を0するだけだ。
`torch`では`relu()`でこれができる。

```{r}
t <- torch_tensor(c(-2, 1, 5, -7))
```

なぜこれが非線型なのか。
線型である規準の一つは、二つの入力に対し先に加えてから変換しても、先に個々の入力を変換してから加えても結果が同じになることだ。
ReLUではそのようにはならない。

```{r}
t1 <- torch_tensor(c(1, 2, 3))
t2 <- torch_tensor(c(1, -2, 3))

t1$add(t2)$relu()
```

```{r}
t1_clamped <- t1$relu()
t2_clamped <- t2$relu()

t1_clamped$add(t2_clamped)
```

結果は同じではない。

これまでをまとめると、層を重ねて活性化函数を作用されることを説明した。
あと一つ概念を示してからネットワークを完成される。
その概念とは損失函数だ。

## 損失函数

抽象的にいえば、損失とは目的からどれくらい離れているかという尺度だ。
函数を最小化するとき、前の章で行ったように、これは現在の函数値と取りうる最小の値との差である。
ニューラルネットワークでは、目的に適合している限り損失函数を自由に選ぶことができる。
回帰問題では、平均二乗誤差（MSE: mean square error）がよく用いられるが、それには限らない。
平均絶対誤差を代わりに用いるべきこともあるだろう。

`torch`では、平均二乗誤差は一行で書ける。

```{r}
y <- torch_randn(5)
y_pred <- y + 0.01

loss <- (y_pred - y)$pow(2)$mean()

loss
```

損失函数が決まれば、重みの更新は勾配に比例した一部を引くことでできる。
やり方は既に前の章で見たが、すぐにまた行うことになる。

それでは説明した部品を集めて組み立てよう。

## ネットワークの実装

実装は三つの部分に分かれる。
こうしておくと、後で`torch`の高レベルの機能を利用してそれぞれの部分を改訂する際に、カプセル化やモジュール化が行われる部分が分かりやすい。

### ランダムデータの生成

例として使うデータは百個の観測からなる。
入力`x`は三つの特徴量を持つ。
目的`y`は一つの値で、`y`は`x`から生成されるが、ノイズが加えられる。

```{r}
library(torch)

# 入力次元（入力の特徴量の数）
d_in <- 3
# 訓練集合の観測数
n <- 100

x <- torch_randn(n, d_in)
coefs <- c(0.2, -1.3, -0.5)
y <- x$matmul(coefs)$unsqueeze(2) + torch_randn(n, 1)
```

### ネットワークの構築

ネットワークは隠れ層と出力層の二層とする。
つまり二つの重み行列と二つのバイアステンソルが必要である。
特に理由はないが、隠れ層には三十二ユニット配置する。

```{r}
# 隠れ層の次元
d_hidden <- 32
# 出力次元（予測される特徴量の数）
d_out <- 1

# 入力を隠れ層に結合する重み
w1 <- torch_randn(d_in, d_hidden, requires_grad = TRUE)
# 隠れ層を出力に結合する重み
w2 <- torch_randn(d_hidden, d_out, requires_grad = TRUE)

# 隠れ層のバイアス
b1 <- torch_zeros(1, d_hidden, requires_grad = TRUE)
# 出力層のバイアス
b2 <- torch_zeros(1, d_out, requires_grad = TRUE)
```

現在の値、乱数初期化の結果は、重みとバイアスは有用ではない。
ネットワークを訓練する時が来た。

### ネットワークの訓練

ネットワークの訓練は入力を層に伝播させ、損失を計算し、パラメタ（重みとバイアス）を調整して、予測を向上するようにする事である。
性能が十分（実際の応用では、非常に注意深く定義する必要がある）と思われるまで、これらの計算を繰り返す。
技術的には、これらの手順を反復して適用する各回を *エポック* と呼ぶ。

函数の最小化のように、適切な学習率（差し引く勾配の比率）は実験的によって決める。

以下に示す訓練ループを見ると、必然的に四つの部分に分かれることが分かる。

* 順伝播してネットワークの予測を得る（一行に書くのが好みでないなら、分けて書いてもよい）。
* 損失を計算する（これも一行で、いくらかのログ出力を追加しただけだ）。
* *autograd* に損失のバラメタに対する勾配を計算させる。
* パラメタを適切に更新する（ここでも全ての演算を`with_no_grad()`で囲み、`grad`フィールドを反復ごとにゼロにしている）。

```{r}
learning_rate <- 1e-4

### 訓練ループ----------------------------------------

for (t in 1:200) {
  
  ### ------- 順伝播 -------
  
  y_pred <- x$mm(w1)$add(b1)$relu()$mm(w2)$add(b2)
  
  ### ------- 損失の計算 -------
  loss <- (y_pred - y)$pow(2)$mean()
  if (t %% 10 == 0)
    cat("Epoch: ", t, "   Loss: ", loss$item(), "\n")
  
  ### ------- 逆伝播 -------
  
  # `requires_grad = TRUE がついた
  # 全てのデンソルについて損失の勾配を計算
  loss$backward()
  
  ### ------- 重みの更新 -------
  
  # この部分は自動勾配計算のために記録したくない部分なので
  # with_no_grad()で囲む。
  
  with_no_grad({
    w1 <- w1$sub_(learning_rate * w1$grad)
    w2 <- w2$sub_(learning_rate * w2$grad)
    b1 <- b1$sub_(learning_rate * b1$grad)
    b2 <- b2$sub_(learning_rate * b2$grad)
    
    # 伝播ごとにゼロにする。
    # そうしないと蓄積してしまう。
    w1$grad$zero_()
    w2$grad$zero_()
    b1$grad$zero_()
    b2$grad$zero_()
  })

}
```

損失は最初急速に減少し、その後それほど速く減少なくなる。
この例はすばらしい性能を示すために作られたのでなく、わずかな行のコードで「本物の」ニューラルネットワークが構築できることを示すことが意図である。

層や、損失、パラメタ更新はまだかなら粗削りで、（文字通り）単なるテンソルである。
このような小さなネットワークには問題だが、より複雑な設計ではすぐに面倒になる。
以下の二つの章では、重みとバイアスをネットワークに抽象化し、自作の損失函数を組込のものに取り替え、冗長なパラメタ更新部分を取り除く。