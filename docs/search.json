[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "R torchによる深層学習と科学計算",
    "section": "",
    "text": "Welcome!\n\nThis is the on-line edition of Deep Learning and Scientific Computing with R torch, written by Sigrid Keydana. Visit the GitHub repository for this site, or buy a physical copy from the publisher, CRC Press. You’ll also find the book at the usual outlets, e.g., Amazon.\nThis on-line work is licensed under a Creative Commons Attribution-NonCommercial-ShareAlike 4.0 International License.\n\nPreface\nThis is a book about torch, the R interface to PyTorch. PyTorch, as of this writing, is one of the major deep-learning and scientific-computing frameworks, widely used across industries and areas of research. With torch, you get to access its rich functionality directly from R, with no need to install, let alone learn, Python. Though still “young” as a project, torch already has a vibrant community of users and developers; the latter not just extending the core framework, but also, building on it in their own packages.\nIn this text, I’m attempting to attain three goals, corresponding to the book’s three major sections.\nThe first is a thorough introduction to core torch: the basic structures without whom nothing would work. Even though, in future work, you’ll likely go with higher-level syntactic constructs when possible, it is important to know what it is they take care of, and to have understood the core concepts. What’s more, from a practical point of view, you just need to be “fluent” in torch to some degree, so you don’t have to resort to “trial-and-error-programming” too often.\nIn the second section, basics explained, we proceed to explore various applications of deep learning, ranging from image recognition over time series and tabular data to audio classification. Here, too, the focus is on conceptual explanation. In addition, each chapter presents an approach you can use as a “template” for your own applications. Whenever adequate, I also try to point out the importance of incorporating domain knowledge, as opposed to the not-uncommon “big data, big models, big compute” approach.\nThe third section is special in that it highlights some of the non-deep-learning things you can do with torch: matrix computations (e.g., various ways of solving linear-regression problems), calculating the Discrete Fourier Transform, and wavelet analysis. Here, more than anywhere else, the conceptual approach is very important to me. Let me explain.\nFor one, I expect that in terms of educational background, my readers will vary quite a bit. With R being increasingly taught, and used, in the natural sciences, as well as other areas close to applied mathematics, there will be those who feel they can’t benefit much from a conceptual (though formula-guided!) explanation of how, say, the Discrete Fourier Transform works. To others, however, much of this may be uncharted territory, never to be entered if all goes its normal way. This may hold, for example, for people with a humanist, not-traditionally-empirically-oriented background, such as literature, cultural studies, or the philologies. Of course, chances are that if you’re among the latter, you may find my explanations, though concept-focused, still highly (or: too) mathematical. In that case, please rest assured that, to the understanding of these things (like many others worthwhile of understanding), it is a long way; but we have a life’s time.\nSecondly, even though deep learning has been “the” paradigm of the last decade, recent developments seem to indicate that interest in mathematical/domain-based foundations is (again – this being a recurring phenomenon) on the rise (Consider, for example, the Geometric Deep Learning approach, systematically explained in Bronstein et al. (2021), and conceptually introduced in Beyond alchemy: A first look at geometric deep learning.) In the future, I assume that we’ll likely see more and more “hybrid” approaches that integrate deep-learning techniques and domain knowledge. The Fourier Transform is not going away.\nLast but not least, on this topic, let me make clear that, of course, all chapters have torch code. In case of the Fourier Transform, for example, you’ll see not just the official way of doing this, using dedicated functionality, but also, various ways of coding the algorithm yourself – in a surprisingly small number of lines, and with highly impressive performance.\nThis, in a nutshell, is what to expect from the book. Before I close, there is one thing I absolutely need to say, all the more since even though I’d have liked to, I did not find occasion to address it much in the book, given the technicality of the content. In our societies, as adoption of machine/deep learning (“AI”) is growing, so are opportunities for misuse, by governments as well as private organizations. Often, harm may not even be intended; but still, outcomes can be catastrophic, especially for people belonging to minorities, or groups already at a disadvantage. Like that, even the inevitable, in most of today’s political systems, drive to make profits results in, at the very least, societies imbued with highly questionable features (think: surveillance, and the “quantification of everything”); and most likely, in discrimination, unfairness, and severe harm. Here, I cannot do more than draw attention to this problem, point you to an introductory blog post that perhaps you’ll find useful: Starting to think about AI Fairness, and just ask you to, please, be actively aware of this problem in public life as well as your own work and applications.\nFinally, let me end with saying thank you. There are far too many people to thank that I could ever be sure I haven’t left anyone out; so instead I’ll keep this short. I’m extremely grateful to my publisher, CRC Press (first and foremost, David Grubbs and Curtis Hill) for the extraordinarily pleasant interactions during all of the writing and editing phases. And very special thanks, for their support related to this book as well as their respective roles in the process, go to Daniel Falbel, the creator and maintainer of torch, who in-depth reviewed this book and helped me with many technical issues; Tracy Teal, my manager, who supported and encouraged me in every possible way; and Posit (formerly, RStudio), my employer, who lets me do things like this for a living.\nSigrid Keydana\n\n\n\n\nBronstein, Michael M., Joan Bruna, Taco Cohen, and Petar Velickovic. 2021. “Geometric Deep Learning: Grids, Groups, Graphs, Geodesics, and Gauges.” CoRR abs/2104.13478. https://arxiv.org/abs/2104.13478.",
    "crumbs": [
      "Preface"
    ]
  },
  {
    "objectID": "overview.html",
    "href": "overview.html",
    "title": "1  概要",
    "section": "",
    "text": "本書は三部からなる。 第二部と第三部は、それぞれ深層学習の様々な応用例と基本的な科学計算技術を調査する。 その前に、第一部ではtorchの基本的な構成要素である、テンソルや自動微分、最適化法、モジュールについて学ぶ。 この部分を「torchの基礎」、よくある雛型に従って「torchを始める」にすることもできたが、これらが誤った印象を与えると考えた。 これらは確かに基礎ではあるが、基盤としての基礎である。 これらの章を勉強すれば、torchがどのように動いているかしっかりとした概念が身につき、後の節に現れるより複雑な例をいじるのに支障がない程度までコードに馴染むことができる。 言い換えれば、ある程度torchに 堪能 になれる。\nまた、ニューラルネットワークを一度や二度、白紙から書くことになる。 最初は、単なるテンソルそのものとそれが備える機能を使う 次は、ニューラルネットワークの学習に不可欠な機能をオブジェクト指向でカプセル化した、torchの専用の構造を利用する。 結果として、第二部に進む準備が周到に整い、そこで深層学習を様々な問題や分野に適用する。",
    "crumbs": [
      "torchに慣れる",
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>概要</span>"
    ]
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "2  torchとその入手方法",
    "section": "",
    "text": "2.1 torchの世界\ntorchはPyTorchをRに移植したものである。 PyTorchは、（執筆時点で）産業や研究で最もよく使われている二つの深層学習フレームワークのうちの一つである。 その設計から、様々な科学計算の問題（その一部を本書の最終部で扱う）で有用なすばらしい道具でもある。 torchはRとC++（少しのCを含む）だけで書かれており、これを使うためにPythonをインストールする必要はない。\nPython（PyTorch）の側では、エコシステムは同心円状になっている。 中にPyTorch自体、これなしでは何も動作しない中心ライブラリがある。 これを取り囲むのは、フレームワークライブラリと呼ばれる内側の円があり、特別なデータの種類に特化しているか、運用のような仕事の流れの問題を中心据えている。 さらに、より広範なアドオンや特化したコード、ライブラリのエコシステムがあり、それはPyTorchを構成要素やツールとして使っている。\nRの側では同一の「心臓」を用いている。 全てはtorchのコアに依存している。 Rでも類似のライブラリがあるが、カテゴリの「円」は互いに明確に定められておらず、境界ははっきりとしていない。 活発な開発者のコミュニティがあり、出自や目的も様々だか、さらにtorchを開発して拡張するために共同で活動し、より多くの人々がそれぞれの目的の達成を手助けしている。 エコシステムは急速に成長しており、個々のパッケージに言及することは控えるが、torchのウェブサイトを訪れれば、その一部が掲示されている。\n三つのパッケージについては、名前をあげ、本書で利用する。 それらはtorchvision、torchaudioとluzである。 最初の二つは用途を特定した変換、深層学習モデル、データセット、それぞれ画像（動画を含む）及び音声データのユーティリティを集めたものである。 三番目はtorchの高水準で直感的、使いやすいインターフェースで、ニューラルネットワークの定義、訓練、評価がわずか数行でできる。 torch自体のように三つのパッケージはCRANからインストールできる。",
    "crumbs": [
      "torchに慣れる",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>`torch`とその入手方法</span>"
    ]
  },
  {
    "objectID": "about.html#torchのインストールと実行",
    "href": "about.html#torchのインストールと実行",
    "title": "2  torchとその入手方法",
    "section": "2.2 torchのインストールと実行",
    "text": "2.2 torchのインストールと実行\ntorchはWindows、macOSとLinuxで利用できる。 対応するGPUと必要なNVIDAのソフトウェアがインストールされていれば、訓練されたモデルの種類次第で、かなりの高速化の恩恵を得られる。 本書の全ての例は、CPUで実行できるものを選び、読者が辛抱強く待つ必要がないようにした。\n適合性の問題は一時的なものであるため、本書ではここに記さない。 同様に具体的なインストールの手順を羅列することも控える。 いつでも最新情報はvignetteから得られる。 問題や質問があれば、torchのGitHubリポジトリに遠慮なくissueを立ててほしい。",
    "crumbs": [
      "torchに慣れる",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>`torch`とその入手方法</span>"
    ]
  },
  {
    "objectID": "tensors.html",
    "href": "tensors.html",
    "title": "3  テンソル",
    "section": "",
    "text": "3.1 テンソルとは何か\ntorchで何か役に立つことをするには、テンソルについて知る必要がある。 数学や物理の意味のテンソルではない。 TensorFlowや (Py-)Torchのような深層学習フレームワークでは、 テンソル は「単なる」多次元配列で、CPUだけでなく、GPUやTPUのような専用の装置上での高速計算に最適化されたものだ。\n実際、torchのtensorは、Rのarrayに同様に任意の次元を取れる。 Rのarrayとは異なり、高速かつ大規模に計算を実行するために、GPUに移すことができる（おまけに、自動微分ができるので、大変有用だ）。\ntensorはR6オブジェクトに類似していて、$によりフィールドやメソッドを利用できる。\nlibrary(torch)\n\nt1 &lt;- torch_tensor(1)\nt1\n\ntorch_tensor\n 1\n[ CPUFloatType{1} ]\nこれは単一の値1だけを格納したテンソルだ。 CPUに「生息」しており、その型はFloat。 次に波括弧の中の1{1}に着目する。 これはテンソルの値を改めて示したものではない。 これはテンソルの形状、つまりそれが生息する空間と次元の長さである。 Base Rと同様にベクトルは単一の要素だけでもよい （base Rは1とc(1)を区別しないことを思い出してほしい）。\n前述の$記法を使って、一つ一つ関連するフィールドを参照することで、個別に以上の属性を確認できる。\nt1$dtype\n\ntorch_Float\nt1$device\n\ntorch_device(type='cpu')\nt1$shape\n\n[1] 1\nテンソルの $to() を使うと、メソッドいくつかの属性は直接変更できる。\nt2 &lt;- t1$to(dtype = torch_int())\nt2$dtype\n\ntorch_Int\n# GPUがある場合\n#t2 &lt;- t1$to(device = \"GPU\")\n# Apple Siliconの場合\nt2 &lt;- t1$to(device = \"mps\")\nt2$device\n\ntorch_device(type='mps', index=0)\n形状の変更はどのようにするのか。 これは別途扱うに値する話題だが、手始めにいじってみることにする。 値の変更なしに、この1次元の「ベクトルテンソル」を2次元の「行列テンソル」にできる。\nt3 &lt;- t1$view(c(1, 1))\nt3$shape\n\n[1] 1 1\n概念的には、Rで1要素のベクトルや行列を作るのに似ている。\nc(1)\n\n[1] 1\n\nmatrix(1)\n\n     [,1]\n[1,]    1\nテンソルがどのようなものか分かったところで、いくつかのテンソルを作る方法について考えてみる。",
    "crumbs": [
      "torchに慣れる",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>テンソル</span>"
    ]
  },
  {
    "objectID": "tensors.html#テンソルの作成",
    "href": "tensors.html#テンソルの作成",
    "title": "3  テンソル",
    "section": "3.2 テンソルの作成",
    "text": "3.2 テンソルの作成\n既に見たテンソルを作る一つの方法はtorch_tensor()を呼び出し、Rの値を渡すというものだった。 この方法は多次元オブジェクトに適用でき、以下にいくつかの例を示す。\nしかし、多くの異なる値を渡す必要があるときは効率が悪くなる。 ありがたいことに、値が全て同一であるべき場合や、明示的なパターンに従うときに適用できる別の方法がある。 この節ではこの技についても説明する。\n\n3.2.1 値からテンソル\n前の例では単一要素のベクトルをtorch_tensor()に渡したが、より長いベクトルを同様に渡すことができる。\n\ntorch_tensor(1:5)\n\ntorch_tensor\n 1\n 2\n 3\n 4\n 5\n[ CPULongType{5} ]\n\n\n同様に規定のデバイスはCPUだが、最初からGPU/MPSに配置するテンソルを作成することもできる。\n\n#torch_tensor(1:5, device = \"cuda\")\ntorch_tensor(1:5, device = \"mps\")\n\ntorch_tensor\n 1\n 2\n 3\n 4\n 5\n[ MPSLongType{5} ]\n\n\nこれまで作ってきたのはベクトル。 行列、つまり2次元テンソルはどうやって作るのか。\nRの行列を同様に渡せばよい。\n\ntorch_tensor(matrix(1:9, ncol = 9))\n\ntorch_tensor\n 1  2  3  4  5  6  7  8  9\n[ CPULongType{1,9} ]\n\n\n結果を見てほしい。 1から9までの数字は、列ごとに表示されている。 これは意図通りかもしれないし、そうではないかもしれない。 意図と異なる場合はmatrix()にbyrow = TRUEを渡せばよい。\n\ntorch_tensor(matrix(1:9, ncol = 3, byrow = TRUE))\n\ntorch_tensor\n 1  2  3\n 4  5  6\n 7  8  9\n[ CPULongType{3,3} ]\n\n\n高次元のデータはどうするか。 同様の方針に従って、配列を渡すことができる。\n\ntorch_tensor(array(1:24, dim = c(4, 3, 2)))\n\ntorch_tensor\n(1,.,.) = \n   1  13\n   5  17\n   9  21\n\n(2,.,.) = \n   2  14\n   6  18\n  10  22\n\n(3,.,.) = \n   3  15\n   7  19\n  11  23\n\n(4,.,.) = \n   4  16\n   8  20\n  12  24\n[ CPULongType{4,3,2} ]\n\n\nこの場合でも、結果はRの埋め方に沿ったものとなる。 これが求めるものではないなら、テンソルを構築するプログラムを書いた方が簡単かもしれない。\n慌てる前に、その必要が非常に稀であることを考えてみてほしい。 実際は、Rのデータセットからテンソルを作ることがほとんどだ。 「データセットからテンソル」の最後の小節で詳しく確認する。 その前に、少し時間をとって最後の出力を少し吟味しよう。\n {#fig-tensor-432} 私たテンソルは以下のように印字される。\n\narray(1:24, dim = c(4, 3, 2))\n\n, , 1\n\n     [,1] [,2] [,3]\n[1,]    1    5    9\n[2,]    2    6   10\n[3,]    3    7   11\n[4,]    4    8   12\n\n, , 2\n\n     [,1] [,2] [,3]\n[1,]   13   17   21\n[2,]   14   18   22\n[3,]   15   19   23\n[4,]   16   20   24\n\n\n上のテンソルの印字と比較しよう。 Arrayとtensorは異なる方向にオブジェクトを切っている。 テンソルは値を3x2の上向きと奥に向かう広がる長方形に切り、4つの\\(x\\)のそれぞれの値に対して一つ示している。 一方、配列はzの値で分割し、二つの奥向きと右向きに進む大きな4x3の部分を示す。\n言い換えれば、テンソルは左/「外側」から、配列は右/「内側」から思考を始めているとも言えるだろう。\n\n\n3.2.2 指定からテンソル\ntorchの大口生成函数が便利な状況は、おおまかに二つある。 一つは、テンソルの個々の値は気にせず、分布のみに興味がある場合だ。 もう一つは、ある一定のパターンに従う場合だ。\n要素の値の代わりに、大口生成函数を使うときは、取るべき形状を指定する。 例えば、3x3のテンソルを生成し、標準正規分部の値で埋める場合は次のようにする。\n\ntorch_randn(3, 3)\n\ntorch_tensor\n 0.0844  0.2884  0.3855\n 0.8092 -0.9141  0.0467\n-1.7020  0.8729  0.6844\n[ CPUFloatType{3,3} ]\n\n\n次に示すのは、0と1の間の一様分布に対する同様なもの。\n\ntorch_rand(3, 3)\n\ntorch_tensor\n 0.3276  0.5502  0.3535\n 0.0364  0.1651  0.7390\n 0.6300  0.4114  0.3126\n[ CPUFloatType{3,3} ]\n\n\n全て1や0からなるテンソルが必要となることがよくある。\n\ntorch_zeros(2, 5)\n\ntorch_tensor\n 0  0  0  0  0\n 0  0  0  0  0\n[ CPUFloatType{2,5} ]\n\n\n\ntorch_ones(2, 2)\n\ntorch_tensor\n 1  1\n 1  1\n[ CPUFloatType{2,2} ]\n\n\n他にも多くの大口生成函数がある。 最後に線型代数で一般的ないくつかの行列を作る方法を見ておく。 これは単位行列。\n\ntorch_eye(n = 5)\n\ntorch_tensor\n 1  0  0  0  0\n 0  1  0  0  0\n 0  0  1  0  0\n 0  0  0  1  0\n 0  0  0  0  1\n[ CPUFloatType{5,5} ]\n\n\nそしてこれは対角行列。\n\ntorch_diag(c(1, 2, 3))\n\ntorch_tensor\n 1  0  0\n 0  2  0\n 0  0  3\n[ CPUFloatType{3,3} ]\n\n\n\n\n3.2.3 データセットからテンソル\nさて、Rのデータセットからテンソルを作る方法を見ていこう。 データセットよっては、この過程は「自動」であったり、考慮や操作が必要になったりする。\nまず、base RについてくるJohnsonJohnsonを試してみる。 これは、Johnson & Johnsonの一株あたりの四半期利益の時系列である。\n\nJohnsonJohnson\n\n      Qtr1  Qtr2  Qtr3  Qtr4\n1960  0.71  0.63  0.85  0.44\n1961  0.61  0.69  0.92  0.55\n1962  0.72  0.77  0.92  0.60\n1963  0.83  0.80  1.00  0.77\n1964  0.92  1.00  1.24  1.00\n1965  1.16  1.30  1.45  1.25\n1966  1.26  1.38  1.86  1.56\n1967  1.53  1.59  1.83  1.86\n1968  1.53  2.07  2.34  2.25\n1969  2.16  2.43  2.70  2.25\n1970  2.79  3.42  3.69  3.60\n1971  3.60  4.32  4.32  4.05\n1972  4.86  5.04  5.04  4.41\n1973  5.58  5.85  6.57  5.31\n1974  6.03  6.39  6.93  5.85\n1975  6.93  7.74  7.83  6.12\n1976  7.74  8.91  8.28  6.84\n1977  9.54 10.26  9.54  8.73\n1978 11.88 12.06 12.15  8.91\n1979 14.04 12.96 14.85  9.99\n1980 16.20 14.67 16.02 11.61\n\n\ntorch_tensor()に渡すだけで、魔法のようにほしいものが手に入るだろうか。\n\ntorch_tensor(JohnsonJohnson)\n\ntorch_tensor\n  0.7100\n  0.6300\n  0.8500\n  0.4400\n  0.6100\n  0.6900\n  0.9200\n  0.5500\n  0.7200\n  0.7700\n  0.9200\n  0.6000\n  0.8300\n  0.8000\n  1.0000\n  0.7700\n  0.9200\n  1.0000\n  1.2400\n  1.0000\n  1.1600\n  1.3000\n  1.4500\n  1.2500\n  1.2600\n  1.3800\n  1.8600\n  1.5600\n  1.5300\n  1.5900\n... [the output was truncated (use n=-1 to disable)]\n[ CPUFloatType{84} ]\n\n\nうまくいっているようだ。 値は希望通り四半期ごとに並んでいる。\n魔法？いや、そうではない。 torchができるのは与えられたものに対して動作することだ。 ここでは、与えられたのは実は四半期順に並んだdoubleのベクトル。 データはtsクラスなので、その通りに印字されただけだ。\n\nunclass(JohnsonJohnson)\n\n [1]  0.71  0.63  0.85  0.44  0.61  0.69  0.92  0.55  0.72  0.77  0.92  0.60\n[13]  0.83  0.80  1.00  0.77  0.92  1.00  1.24  1.00  1.16  1.30  1.45  1.25\n[25]  1.26  1.38  1.86  1.56  1.53  1.59  1.83  1.86  1.53  2.07  2.34  2.25\n[37]  2.16  2.43  2.70  2.25  2.79  3.42  3.69  3.60  3.60  4.32  4.32  4.05\n[49]  4.86  5.04  5.04  4.41  5.58  5.85  6.57  5.31  6.03  6.39  6.93  5.85\n[61]  6.93  7.74  7.83  6.12  7.74  8.91  8.28  6.84  9.54 10.26  9.54  8.73\n[73] 11.88 12.06 12.15  8.91 14.04 12.96 14.85  9.99 16.20 14.67 16.02 11.61\nattr(,\"tsp\")\n[1] 1960.00 1980.75    4.00\n\n\nこれはうまくいった。 別なものを試そう。\n\ndim(Orange)\n\n[1] 35  3\n\n\n\nhead(Orange)\n\n  Tree  age circumference\n1    1  118            30\n2    1  484            58\n3    1  664            87\n4    1 1004           115\n5    1 1231           120\n6    1 1372           142\n\n\n\ntorch_tensor(Orange)\n\nError in torch_tensor_cpp(data, dtype, device, requires_grad, pin_memory): R type not handled\n\n\nどの型が処理されないのか。 「元凶」は順序付き因子の列Treeに違いないのは明らかだ。 先にtorchが因子を扱えるか確認する。\n\nf &lt;- factor(c(\"a\", \"b\", \"c\"), ordered = TRUE)\ntorch_tensor(f)\n\ntorch_tensor\n 1\n 2\n 3\n[ CPULongType{3} ]\n\n\nこれは問題なく動作した。 他に何がありうるか。 ここでの問題は含まれている構造data.structureである。 as.matrix()を先に作用させる必要がある。 でも、因子が存在するので、全て文字列の配列になってしまい、希望通りにならない。 したがって、基礎となるレベル（整数）を抽出してから、data.frameから行列に変換する。\n\n orange_ &lt;- Orange |&gt;\n  transform(Tree = as.numeric(Tree)) |&gt;\n  as.matrix()\n\ntorch_tensor(orange_) |&gt; print(n = 7)\n\ntorch_tensor\n    2   118    30\n    2   484    58\n    2   664    87\n    2  1004   115\n    2  1231   120\n    2  1372   142\n    2  1582   145\n... [the output was truncated (use n=-1 to disable)]\n[ CPUFloatType{35,3} ]\n\n\n同じことを別のdata.frame、modeldataのokcでしてみよう。\n\n\n\n\n\n\nCaution\n\n\n\nokcはmodeldataの0.1.1で廃止となり、0.1.2以降は削除された。\n\n\n\nload(\"data/okc.RData\")\n\nhead(okc)\n\n  age              diet height            location       date Class\n1  22 strictly anything     75 south san francisco 2012-06-28 other\n2  35      mostly other     70             oakland 2012-06-29 other\n3  38          anything     68       san francisco 2012-06-27 other\n4  23        vegetarian     71            berkeley 2012-06-28 other\n5  29              &lt;NA&gt;     66       san francisco 2012-06-27 other\n6  29   mostly anything     67       san francisco 2012-06-29  stem\n\n\n\ndim(okc)\n\n[1] 59855     6\n\n\n二つある整数の列は問題なく、一つある因子の列の扱い方は学んだ。 characterとdateの列はどうだろう。 個別にdateの列からテンソルを作ってみる。\n\nprint(torch_tensor(okc$date), n = 7)\n\ntorch_tensor\n 15519\n 15520\n 15518\n 15519\n 15518\n 15520\n 15516\n... [the output was truncated (use n=-1 to disable)]\n[ CPUFloatType{59855} ]\n\n\nこれはエラーを投げなかったが、何を意味するのか。 こられはRのDateに格納されている実際の値、つまり1970年1月1日からの日数である。 すなわち、技術的には動作する変換だ。 結果が実際に意味をなすかは、どのようにそれを使うつもりかという問題だ。 言い換えれば、おそらく計算に使う前に、これらのデータを追加の処理する必要がある。 どのようにするかは文脈次第。\n次にlocationを見る。 これは、character型の列のうちの一つだ。 そのままtorchに渡すとどうなるか。\n\ntorch_tensor(okc$location)\n\nError in torch_tensor_cpp(data, dtype, device, requires_grad, pin_memory): R type not handled\n\n\n実際torchには文字列を格納するテンソルはない。 これらをnumeric型に本管する何らかの方法を適用する必要がある。 この例のような場合、個々の観測が単一の実体（例えば文やパラグラフではなく）を含む場合、最も簡単な方法はRでfactorに変換し、numeric、そしてtensorにすることだ。\n\nokc$location |&gt;\n  factor() |&gt;\n  as.numeric() |&gt;\n  torch_tensor() |&gt;\n  print(n = 7)\n\ntorch_tensor\n 120\n  74\n 102\n  10\n 102\n 102\n 102\n... [the output was truncated (use n=-1 to disable)]\n[ CPUFloatType{59855} ]\n\n\n確かに、技術的にはこれはうまく動作する。 しかしながら、情報が失われる。 例えば、最初と3番目の場所はそれぞれ”south san francisco”と”san francisco”だ。 一度因子に変換されると、これらは意味の上で”san francisco”や他の場所と同じ距離になる。 繰り返しになるが、これが重要かはデータの詳細と目的次第だ。 これが重要なら、例えば、観測をある基準でまとめたり、緯度/経度に変換したりすることを含めさまざまな対応がありうる。 これらの考慮は全くtorchに特有ではないが、ここで述べたのはtorchの「データ統合フロー」に影響するからだ\n最後に実際のデータ科学の世界に挑むには、NAを無視するわけにはいかない。 確認しよう。\n\ntorch_tensor(c(1, NA, 3))\n\ntorch_tensor\n 1\nnan\n 3\n[ CPUFloatType{3} ]\n\n\nRのNAはNaNに変換された。 これを扱えるだろうか。 いくつかのtorchのかんすうでは可能だ。 例えば、torch_nanquantil()は単にNaNを無視する。\n\ntorch_nanquantile(torch_tensor(c(1, NA, 3)), q = 0.5)\n\ntorch_tensor\n 2\n[ CPUFloatType{1} ]\n\n\nただし、ニューラルネットワークを訓練するなら、欠損値を意味のあるように置き換える方法を考える必要があるが、この話題は後回しにする。",
    "crumbs": [
      "torchに慣れる",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>テンソル</span>"
    ]
  },
  {
    "objectID": "tensors.html#テンソルに対する操作",
    "href": "tensors.html#テンソルに対する操作",
    "title": "3  テンソル",
    "section": "3.3 テンソルに対する操作",
    "text": "3.3 テンソルに対する操作\nテンソルに対する数学的操作は全て可能だ。和、差、積など。 これらの操作は（torch_で始まる）函数や（$記法で呼ぶ）オブジェクトに対するメソッドとして利用可能だ。 次の二つは同じだ。\n\nt1 &lt;- torch_tensor(c(1, 2))\nt2 &lt;- torch_tensor(c(3, 4))\n\ntorch_add(t1, t2)\n\ntorch_tensor\n 4\n 6\n[ CPUFloatType{2} ]\n\n\n\nt1$add(t2)\n\ntorch_tensor\n 4\n 6\n[ CPUFloatType{2} ]\n\n\nどちらも新しいオブジェクトが生成され、t1もt2も変更されない。 オブジェクトをその場で変更する別のメソッドもある。\n\nt1$add_(t2)\n\ntorch_tensor\n 4\n 6\n[ CPUFloatType{2} ]\n\n\n\nt1\n\ntorch_tensor\n 4\n 6\n[ CPUFloatType{2} ]\n\n\n実は、同じパターンは他の演算にも適用される。 アンダスコアが後についているのを見たら、オブジェクトはその場で変号とされる。\n当然、科学計算の場面では行列演算は特に重要だ。 二つの一次元構造、つまりベクトルの内積から始める。\n\nt1 &lt;- torch_tensor(1:3)\nt2 &lt;- torch_tensor(4:6)\nt1$dot(t2)\n\ntorch_tensor\n32\n[ CPULongType{} ]\n\n\nこれは動かないはずだと考えただろうか。 テンソルの一つを転置（torch_t()）する必要があっただろうか。 これも動作する。\n\nt1$t()$dot(t2)\n\ntorch_tensor\n32\n[ CPULongType{} ]\n\n\n最初の呼び出しも動いたのは、torchが行ベクトルと列ベクトルを区別しないからだ。 結果として、torch_matmul()を使ってベクトルを行列にかけるときも、ベクトルの向きを心配する必要はない。\n\nt3 &lt;- torch_tensor(matrix(1:12, ncol = 3, byrow = TRUE))\nt3$matmul(t1)\n\ntorch_tensor\n 14\n 32\n 50\n 68\n[ CPULongType{4} ]\n\n\n同じ函数torch_matmul()は二つの行列をかけるときにも使う。 これがtorch_multiply()の動作、つまり引数のスカラ積とどのように異なるかよく見てほしい。\n\ntorch_multiply(t1, t2)\n\ntorch_tensor\n  4\n 10\n 18\n[ CPULongType{3} ]\n\n\nテンソル演算は他にも多数あり、勉強の途中、いくつかに出会うことになるか、特に述べておく必要な集まりが一つある。\n\n3.3.1 集計\nR行列に対して和を計算する場合、それは次の三つのうちの一つを意味する。 総和、行の和、もしくは列の和。 これら三つを見てみよう（訳あってapply()を使う）。\n\nm &lt;- outer(1:3, 1:6)\n\nsum(m)\n\n[1] 126\n\napply(m, 1, sum)\n\n[1] 21 42 63\n\napply(m, 2, sum)\n\n[1]  6 12 18 24 30 36\n\n\nそれではtorchで同じことをする。 総和から始める。\n\nt &lt;- torch_outer(torch_tensor(1:3), torch_tensor(1:6))\nt$sum()\n\ntorch_tensor\n126\n[ CPULongType{} ]\n\n\n行と列の和は面白くなる。 dim引数はtorchにどの次元の和をとるか伝える。 dim = 1を渡すと次のようになる。\n\nt$sum(dim = 1)\n\ntorch_tensor\n  6\n 12\n 18\n 24\n 30\n 36\n[ CPULongType{6} ]\n\n\n予想外にも列の和になった。 結論を導く前に、dim = 2だとどうなるか。\n\nt$sum(dim = 2)\n\ntorch_tensor\n 21\n 42\n 63\n[ CPULongType{3} ]\n\n\n今度は行の和である。 torchの次元の順序を誤解したのだろうか。そうではない。 torchでは、二つの次元があれば行が第一で列が第二である （すぐに示すように、添え字はRで一般的なのと同じで1から始まる）。\nむしろ、概念の違いは集計にある。 Rにおける集計は、頭の中にあるものをよく特徴づけている。 行（次元1）ごとに集計して行のまとめを得て、列（次元2）ごとに集計した列のまとめを得る。 torchでは考え方が異なる。 列（次元2）を圧縮して行のまとめを計算し、行（次元1）で列のまとめを得る。\n同じ考え方がより高い次元に対しても適用される。 例えば、4人の時系列データを記録しているとする。 二つの特徴量を3回計測する。 再帰型ニューラルネットワーク（詳しくは後ほど）を訓練する場合、測定を次のように並べる。\n\n次元1: 個人に亙る。\n次元2: 時刻に亙る。\n次元3: 特徴に亙る。\n\nテンソルは次のようになる。\n\nt &lt;- torch_randn(4, 3, 2)\nt\n\ntorch_tensor\n(1,.,.) = \n -0.1955 -1.0655\n  1.6992  0.6136\n  0.7315 -0.4752\n\n(2,.,.) = \n  0.7349  0.4085\n -1.5968 -2.3491\n -0.6444 -0.6824\n\n(3,.,.) = \n  0.8991 -2.7478\n  0.7731  0.8421\n  0.3377  0.2671\n\n(4,.,.) = \n -0.7625 -0.0048\n  0.4914  1.3579\n  0.5648 -0.4316\n[ CPUFloatType{4,3,2} ]\n\n\n二つの特徴量についての平均は、対象と時刻に独立で、次元1と2を圧縮する。\n\nt$mean(dim = c(1, 2))\n\ntorch_tensor\n 0.2527\n-0.3556\n[ CPUFloatType{2} ]\n\n\n一方、特徴量について平均を求めるが、各個人に対するものは次のように計算する。\n\nt$mean(dim = 2)\n\ntorch_tensor\n 0.7451 -0.3090\n-0.5021 -0.8743\n 0.6700 -0.5462\n 0.0979  0.3072\n[ CPUFloatType{4,2} ]\n\n\nここで圧縮されたは時刻である。",
    "crumbs": [
      "torchに慣れる",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>テンソル</span>"
    ]
  },
  {
    "objectID": "tensors.html#テンソルの部分参照",
    "href": "tensors.html#テンソルの部分参照",
    "title": "3  テンソル",
    "section": "3.4 テンソルの部分参照",
    "text": "3.4 テンソルの部分参照\nテンソルを使っていると、計算のある部分が入力テンソルの一部にのみに対する演算であることはよくある。 その部分が単一の実体（値、行、列など）なら添字参照、このような実体の範囲なら切り出しと呼ばれる。\n\n3.4.1 「R思考」\n添字参照も切り出しも基本的にはRと同じように働く。 いくつかの拡張された記法を続く節で示すが、総じてふるまいは直感に反しない。\nなぜならRと同じように、torchでも添字は1から始まるし、1要素になった次元は落とされるからだ。\n下の例では、2次元テンソルの最初の行を求め、その結果1次元つまりベクトルを得る。\n\nt &lt;- torch_tensor(matrix(1:9, ncol = 3, byrow = TRUE))\nt[1, ]\n\ntorch_tensor\n 1\n 2\n 3\n[ CPULongType{3} ]\n\n\nただし、drop = FALSEを指定すると次元は保持される。\n\nt[1, , drop = FALSE]\n\ntorch_tensor\n 1  2  3\n[ CPULongType{1,3} ]\n\n\n切り出しの時は、1要素となる次元はないので、他に考慮すべきことはない。\n\nt &lt;- torch_rand(3, 3, 3)\nt[1:2, 2:3, c(1, 3)]\n\ntorch_tensor\n(1,.,.) = \n  0.8836  0.5528\n  0.1589  0.3730\n\n(2,.,.) = \n  0.5319  0.5700\n  0.2963  0.1182\n[ CPUFloatType{2,2,2} ]\n\n\nまとめると、添字参照と切り出しはほぼRと同じように働く。 次に、前に述べた、さらに使いやすくする拡張について見る。\n\n\n3.4.2 Rを越える\n拡張の一つはテンソルの最後の要素の参照だ。 利便性のため、torchでは-1を使ってそれができる。\n\nt &lt;- torch_tensor(matrix(1:4, ncol = 2, byrow = TRUE))\nt[-1, -1]\n\ntorch_tensor\n4\n[ CPULongType{} ]\n\n\n注意すべきは、Rでは負の添字はかなり異なった効果を持ち、対応する位置の要素は取り除かれることだ。\nもう一つの便利な機能は、切り出しの記法で刻み幅を二つ目のコロンの後に指定できることだ。 ここでは、一つ目から八つ目の列を一つおきに取り出している。\n\nt &lt;- torch_tensor(matrix(1:20, ncol = 10, byrow = TRUE))\nt[ , 1:8:2]\n\ntorch_tensor\n  1   3   5   7\n 11  13  15  17\n[ CPULongType{2,4} ]\n\n\n最後に示すのは、同じコードを異なる次元のテンソルに対して動作させる方法だ。 この場合、..を使って明示的に参照されていない、存在する次元全てをまとめて指定できる。\n例えば、行列、配列、もしくは高次元の構造など、どんなテンソルが渡されても最初の次元の添字参照をしたいとする。 次の\nt[1, ..]\nは全てに対して機能する。\n\nt1 &lt;- torch_randn(2, 2)\nt2 &lt;- torch_randn(2, 2, 2)\nt3 &lt;- torch_randn(2, 2, 2, 2)\nt1[1, ..]\n\ntorch_tensor\n 0.4360\n 0.2234\n[ CPUFloatType{2} ]\n\nt2[1, ..]\n\ntorch_tensor\n 0.3650  0.6503\n 1.0185  0.8565\n[ CPUFloatType{2,2} ]\n\nt3[1, ..]\n\ntorch_tensor\n(1,.,.) = \n -0.7810  0.1622\n  0.5846  1.3814\n\n(2,.,.) = \n -0.8020 -1.2546\n -1.0844 -0.7179\n[ CPUFloatType{2,2,2} ]\n\n\n最後の次元の添字参照がしたければ、代わりにt[.., 1]と書けばよい。 両方を組み合わせることもできる。\n\nt3[1, .., 2]\n\ntorch_tensor\n 0.1622  1.3814\n-1.2546 -0.7179\n[ CPUFloatType{2,2} ]\n\n\n次の話題は、添字参照や切り出しと同じくらい重要なテンソルの変形だ。",
    "crumbs": [
      "torchに慣れる",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>テンソル</span>"
    ]
  },
  {
    "objectID": "tensors.html#テンソルの変形",
    "href": "tensors.html#テンソルの変形",
    "title": "3  テンソル",
    "section": "3.5 テンソルの変形",
    "text": "3.5 テンソルの変形\n24要素のテンソルがあるとする。 形状はどうなっているか。 次の可能性がある。\n\n長さ24のベクトル\n24 x 1、12 x 2、6 x 4などの行列\n24 x 1 x 1, 12 x 2 x 1などの3次元配列\nその他（24 x 1 x 1 x 1 x 1という可能性もありうる）\n\n値をお手玉しなくても、view()メソッドでテンソルの形状を変更できる。 最初のテンソルは長さ24のベクトルとする。\n\nt &lt;- torch_zeros(24)\nprint(t, n = 3)\n\ntorch_tensor\n 0\n 0\n 0\n... [the output was truncated (use n=-1 to disable)]\n[ CPUFloatType{24} ]\n\n\n同じベクトルを横長の行列に変形する。\n\nt2 &lt;- t$view(c(2, 12))\n\n新しいテンソルt2を得たが、興味深いことに（そして性能の上で重要なことに）、torchはその値に対して新たに記憶域を割り付ける必要がなかったことだ。 自分で確認することができる。 二つのテンソルはデータほ同じ場所に格納している。\n\nt$storage()$data_ptr()\n\n[1] \"0x13e7fa140\"\n\nt2$storage()$data_ptr()\n\n[1] \"0x13e7fa140\"\n\n\nどのように実現されているか少し議論する。\n\n3.5.1 複製なし変形と複製あり変形\ntorchにテンソルの変形をさせると、テンソルの中身に対して新たな記憶域を割り付けずに要求を達成しようとする。 これが実現可能なのは、同じデータ、究極的には同じバイト列は異なる方法で読み出すことができるからだ。 必要なのはメタデータの記憶域だけだ。\ntorchはどのようにしているか。 具体的な例を見てみる。 3 x 5行列から始める。\n\nt &lt;- torch_tensor(matrix(1:15, nrow = 3, byrow = TRUE))\nt\n\ntorch_tensor\n  1   2   3   4   5\n  6   7   8   9  10\n 11  12  13  14  15\n[ CPULongType{3,5} ]\n\n\nテンソルにはstride()メソッドがあり、各次元に対して次の要素にたどり着くまでにいくつの要素を越えたか追跡する。 上記のテンソルtに対して、次の行に進むには5要素飛ばす必要があるが、次の列には一つだけ飛ばせばよい。\n\nt$stride()\n\n[1] 5 1\n\n\nここで、テンソルを変形して、今度は5行3列にする。 データ自体は変化しないことを思い出してほしい。\n\nt2 &lt;- t$view(c(5, 3))\nt2\n\ntorch_tensor\n  1   2   3\n  4   5   6\n  7   8   9\n 10  11  12\n 13  14  15\n[ CPULongType{5,3} ]\n\n\n今回は次の行には、5要素ではなく3要素だけ飛ばせば次の行に到達する。 次の列に進むのは、ここでも1要素だけ「跳べ」ばよい。\n\nt2$stride()\n\n[1] 3 1\n\n\nここで、要素の順序を変えることができるか考えてみよう。 例えば、行列の転置はメタデータの方法で可能だろうか。\n\nt3 &lt;- t$t()\nt3\n\ntorch_tensor\n  1   6  11\n  2   7  12\n  3   8  13\n  4   9  14\n  5  10  15\n[ CPULongType{5,3} ]\n\n\n元のテンソルとその転置はメモリ上の同じ場所を指しているので、実際に可能であるはずだ。\n\nt$storage()$data_ptr()\n\n[1] \"0x1069ad1c0\"\n\nt3$storage()$data_ptr()\n\n[1] \"0x1069ad1c0\"\n\n\nこれは道理にかなっている。 次の行に到達するのに、1要素だけ跳び、次の列には5要素跳べばよいから、うまくいくだろう。 確認する。\n\nt3$stride()\n\n[1] 1 5\n\n\nその通りだ。\n可能な限り、torchは形状を変更する演算をこの方法で扱おうとする。\nこのような（今後多数見ることになる）複製なし演算の一つはsqueeze()とその対義語unsqueeeze()だ。 後者は指定位置に単一要素の次元を付け加え、前者は取り除く。 例を挙げる。\n\nt &lt;- torch_randn(3)\nt\n\ntorch_tensor\n 1.5758\n-0.0525\n 1.1578\n[ CPUFloatType{3} ]\n\nt$unsqueeze(1)\n\ntorch_tensor\n 1.5758 -0.0525  1.1578\n[ CPUFloatType{1,3} ]\n\n\nここでは単一要素の次元を前につけた。 代わりに、t$unsqueeze(2)を使えば末尾につけることもできた。\nさて、複製なしの技法は失敗することがあるか。 そのような例を示す。\n\nt &lt;- torch_randn(3, 3)\nt$t()$view(9)\n\nError in (function (self, size) :\nview size is not compatible with input tensor's size and\nstride (at least one dimension spans across two contiguous subspaces).\nUse .reshape(...) instead.\nストライドを変える演算を連続して行うと、二つ目は失敗する可能性が高い。 失敗するかどうか決める方法はあるが、簡単な方法はview()の代わりにreshape()を使うことだ。 後者は魔法のように機能し、可能であればメタデータで、そうでなければ複製する。\n\nt &lt;- torch_randn(3, 3)\nt2 &lt;- t$t()$reshape(9)\n\nt$storage()$data_ptr()\n\n[1] \"0x106c1e400\"\n\nt2$storage()$data_ptr()\n\n[1] \"0x106c1a280\"\n\n\n想像通り、二つのテンソルは今度は異なる場所に格納されている。\nこの長い章の終わりに取り上げる内容は、一見手に余るように見える機能だが、性能の上で極めて重要なものである。 多くのもののように、慣れるには時間が掛かるが、安心してほしい。 この本やtorchを使った多くのプロジェクトでたびたび目にすることになる。 この機能 拡張 （ブロードキャスト） と呼ばれている。",
    "crumbs": [
      "torchに慣れる",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>テンソル</span>"
    ]
  },
  {
    "objectID": "tensors.html#拡張",
    "href": "tensors.html#拡張",
    "title": "3  テンソル",
    "section": "3.6 拡張",
    "text": "3.6 拡張\n形状が厳密に一致しないテンソルに対する演算をすることが多い。\nもちろん、長さ2のベクトルに長さ5のベクトルを足すようなことはしないかもしれない。 でもやってみたいこともありうる。 例えば、全ての要素にスカラを掛けることがあるが、これはできる。\n\nt1 &lt;- torch_randn(3, 5)\nt1 * 0.5\n\ntorch_tensor\n-0.2733 -0.2137  0.2795 -0.4353 -0.3071\n 0.2930 -0.2962 -0.2848  1.1586 -0.2565\n-0.2812 -0.1612  0.6896 -0.0837  0.2188\n[ CPUFloatType{3,5} ]\n\n\nこれはおそらく大したことではなかっただろう。 Rで慣れている。 しかし、次はRでは動作しない。 同じベクトルを行列の全ての行に加えようとしている。\n\nm &lt;- matrix(1:15, ncol = 5, byrow = TRUE)\nm2 &lt;- matrix(1:5, ncol = 5, byrow = TRUE)\n\nm2をベクトルに代えてもうまくいかない。\n\nm3 &lt;- 1:5\n\nm + m3\n\n     [,1] [,2] [,3] [,4] [,5]\n[1,]    2    6    5    9    8\n[2,]    8   12   11   10   14\n[3,]   14   13   17   16   20\n\n\n文法としては動いたが、意味の上では意図した通りではない。\nここで、上の二つをtorchで試してみる。 まず二つのテンソルが2次元の場合（概念的には一つは行ベクトルだが）から。\n\nt &lt;- torch_tensor(m)\nt2 &lt;- torch_tensor(m2)\n\nt$shape\n\n[1] 3 5\n\nt2$shape\n\n[1] 1 5\n\nt$add(t2)\n\ntorch_tensor\n  2   4   6   8  10\n  7   9  11  13  15\n 12  14  16  18  20\n[ CPULongType{3,5} ]\n\n\n次に足すものが1次元テンソルの場合。\n\nt3 &lt;- torch_tensor(m3)\n\nt3$shape\n\n[1] 5\n\nt$add(t3)\n\ntorch_tensor\n  2   4   6   8  10\n  7   9  11  13  15\n 12  14  16  18  20\n[ CPULongType{3,5} ]\n\n\ntorchではどちらも意図通りにうまくいった。 理由を考えてみよう。 上の例でテンソルの形状をあえて印字した。 3 x 5のテンソルには、形状3のテンソルも形状1 x 5のテンソルも足すことができた。 これらは、拡張がどのようにされるか示している。 簡単にいうと、起きたのは次の通りだ。\n\n1 x 5テンソルが加数として使われると、実際は拡張される。 つまり、同じ3行あるかのように扱われる。 このような拡張は一致しない次元が単一で一番左にある場合にのみ実行される。\n形状3のテンソルも同様だが、先に手順が追加される。 大きさが1の主要な次元が実質上左に追加される。 これにより1と同様になり、そこから手順が続く。\n\n重要なのは、物理的な拡張はされないことだ。\nルールを系統だてることにする。\n\n3.6.1 拡張のルール\nルールは次の通り。 まず、一つ目は目を引くものではないか、全ての基礎になる。\n\nテンソルの形状を右に揃える。\n\n二つのテンソル、一つのサイズは3 x 7 x 1、もう一つは1 x 5、があるとする。 これらを右に揃える。\nt1, 形状:     3 7 1\nt2, 形状:       1 5\n\n右から始めて、揃えた軸に沿う大きさが厳密に一致するか、一つが1でなければならない。 後者の場合、単一要素次元のテンソルは単一でないものに対して 拡張 される。\n\n上の例では、拡張は各テンソルに1回ずつ2回発生する。 結果は実質的に以下のようになる。\nt1, 形状:     3 7 5\nt2, 形状:       7 5\n\nもしテンソルの一つが一つ（もしくは1以上）余分な軸があれば、実質的に拡張される。\nt1, 形状: 3 7 5 t2, 形状: 1 7 5\n\nそして拡張が発生する。\nt1, 形状:     3 7 5\nt2, 形状:     3 7 5\nこの例では、拡張が両方のテンソルに同時に発生していることを見た。 覚えておくべきことは、常に右から見るということだ。 次の例は、どんな拡張をしてもうまくいかない。\ntorch_zeros(4, 3, 2, 1)$add(torch_ones(4, 3, 2)) # error\n\nおそらく、この本の中で、この章は最も長く、最も応用から離れたように見えるものだった。 しかし、テンソルに慣れることは、torchをすらすら書くための前提であると言っておく。 同様のことは次の章で扱う話題、自動微分についても言える。 違いは、torchが大変な仕事を我々の代わりにしてくれるということだ。 我々は何をしているか理解すればよいだけだ。",
    "crumbs": [
      "torchに慣れる",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>テンソル</span>"
    ]
  },
  {
    "objectID": "autograd.html",
    "href": "autograd.html",
    "title": "4  自動微分",
    "section": "",
    "text": "4.1 なぜ微分を計算するのか\n教師あり機械学習では、訓練集合が使えて、予測したい変数は既知である。 これが目的変数で真値である。 今予測アルゴリズムを開発し、これを入力変数、予測変数に基づいて訓練する。 この訓練あるいは学習過程は、アルゴリズムの予測と真値とを比べ、 現在の予測がどれくらいよいか悪いか捉える数値が出てくるような比較に基づいている。 この数値を与えるのは、 損失函数 の仕事だ。\n一度現在の損失が分かったら、アルゴリズムはパラメタ、つまりニューラルネットワークの重みを調整して、もっとよい予測にする。 アルゴリズムはどの方向に調整するか知る必要がある。 この情報は、 勾配 つまり微分のベクトルから得られる。\n例として次のような損失函数を想像してみる Figure 4.1。\nこれは二変数の二次函数 f(x_1, x_2) = 0.2x_1^2 + 0.2x_2^2 - 5 である。 最小値は(0,0)で、この点を求める。 白い点で示した点に立ち、風景を眺めれば、坂を速く降る方法は明確に分かる（坂を下るのを恐れないとする）。 でも、最良の方向を計算で見つけるには、勾配を計算する。\n\\(x_1\\)の方向を取り上げる。 \\(x_1\\)に関する函数の微分は、函数値が\\(x_1\\)とともにどのように変化するかを示す。 計算すると\\(\\partial f/ x_1 = 0.4x_1\\)となる。 これは\\(x_1\\)が増えると損失が増えることと、それがどの程度かを示している。 でも損失を減らす必要があるので、逆方向に進む必要がある。\n同じことが\\(x_2\\)軸に対しても成り立つ。 微分を計算すると、\\(\\partial f/\\partial x_2 = 0.4x_2\\)を得る。 再び、微分が示す向きと逆方向を選ぶ。 全体では、降下方向は \\[\n\\begin{bmatrix}\n-0.4x_1\\\\\n-0.4x_2\n\\end{bmatrix}\n\\] である。\nこの方法は最急降下と呼ばれている。 一般的に 勾配降下 と呼ばれ、機械学習で最も基本的な最適化アルゴリズムである。 おそらく直感に反して、最も効率の良い方法ではない。 さらに別の問いがある。 出発点で計算されたこの方向は降下中にずっと最適なのか。 代わりに、定期的に方向を計算し直した方が良いのかもしれない。 このような質問は後の章で検討する。",
    "crumbs": [
      "torchに慣れる",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>自動微分</span>"
    ]
  },
  {
    "objectID": "autograd.html#なぜ微分を計算するのか",
    "href": "autograd.html#なぜ微分を計算するのか",
    "title": "4  自動微分",
    "section": "",
    "text": "Figure 4.1: 仮想的な損失函数（放物面）。",
    "crumbs": [
      "torchに慣れる",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>自動微分</span>"
    ]
  },
  {
    "objectID": "autograd.html#自動微分の例",
    "href": "autograd.html#自動微分の例",
    "title": "4  自動微分",
    "section": "4.2 自動微分の例",
    "text": "4.2 自動微分の例\n微分がなぜ必要か分かったところで、自動微分（AD: automatic differentiation）がどのように計算しているか見てみよう。\n\n\n\n\n\n\nFigure 4.2: 計算グラフの例\n\n\n\nFigure 4.2 は上の函数が計算グラフにどのように表すことができるかを示している。 x1とx2は入力ノードで、対応する函数のパラメタは\\(x_1\\)と\\(x_2\\)である。 xuは函数の出力で、他は全て中間ノードであり正しい順序で実行するために必要である （定数-5、0.2及び2をノードとすることもできるが、定数なので特に気にせずに、簡潔なグラフを選んだ）。\n逆モードADは、torchが実装している自動微分の一種で、まず函数の出力を計算する。 これはグラフの順方向伝播である。 次に逆伝播を行い、両方の入力x1とx2に関する出力の勾配を計算する。 この過程で、右から情報が利用可能となり、積み重なっていく。\n\nx7で、x5とx6に関する偏微分を計算する。 つまり、微分する式は \\(f(x_5, x_6) = x_5 + x_6 - 5\\) なので、偏微分は両方とも1である。\nx5から左に動き、x3にどのように依存しているか確認すると、 \\(\\partial x_5/ \\partial x_3 = 0.2\\)である。 微積分の連鎖律を用いると、出力がどのようにx3に依存するか分かるので、\\(\\partial f/\\partial x_3 = 0.2 \\times 1 = 0.2\\)と計算できる。\nx_3から、xに最後の段階を踏む。 \\(\\partial x_3/ \\partial x_1 = 2x_1\\)なので、連鎖律を再度用いて函数が最初の入力にどのように依存するか定式化できる。 つまり \\(\\partial f/\\partial x_1 = 2x_1 \\times 0.2 \\times 0.1 = 0.4x_1\\) となる。\n同様に二番目の偏微分も計算し、勾配を求める。\\(\\nabla f = (\\partial f/\\partial x_1, \\partial f/\\partial x_2)^\\mathrm{T} = (0.4x_1, 0.4x_2)^\\mathrm{T}\\)\n\nこれが原理である。 実際には、フレームワークによって逆モード自動微分の実装は異なる。 次の節でtorchがどのように実装しているか簡潔に示す。",
    "crumbs": [
      "torchに慣れる",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>自動微分</span>"
    ]
  },
  {
    "objectID": "autograd.html#torch-autograd-による自動微分",
    "href": "autograd.html#torch-autograd-による自動微分",
    "title": "4  自動微分",
    "section": "4.3 torch autograd による自動微分",
    "text": "4.3 torch autograd による自動微分\nまず、用語について注意しておく。 torchではADエンジンは autograd と呼ばれ、本書の残りの多くの部分でもそのように記す。 それでは説明に戻る。\n上述の計算グラフをtorchで構築するには、入力テンソルx1とx2を作成する。 これは興味のあるバラメタを模している。 これまでしてきたように「いつも通り」テンソルを作成すると、torchはAD向けの準備をしない。 そうせずに、これらのテンソルを作るときにrequires_grad = TRUEを渡す必要がある。\n\nlibrary(torch)\n\nx1 &lt;- torch_tensor(2, requires_grad = TRUE)\nx2 &lt;- torch_tensor(2, requires_grad = TRUE)\n\n（ところで二つのテンソルに2という値を選んだのは完全に任意である。）\n次に「隠れた」ノードx3とx6を作るには、二乗して掛け算をする。 最後にx7に最終出力を格納する。\n\nx3 &lt;- x1$square()\nx5 &lt;- x3 * 0.2\n\nx4 &lt;- x2$square()\nx6 &lt;- x4 * 0.2\n\nx7 &lt;- x5 + x6 - 5\nx7\n\ntorch_tensor\n-3.4000\n[ CPUFloatType{1} ][ grad_fn = &lt;SubBackward1&gt; ]\n\n\nrequires_grad = TRUEを追加しなければならなかったのは、入力テンソルを作るときだけであることに注目してほしい。 グラフの依存するノードは全てこの属性を継承する。 確認してみよう。\n\nx7$requires_grad\n\n[1] TRUE\n\n\nこれまでに自動微分が動作するために必要な前提が全て満たされた。 あとはbackward()を呼べぱ、x7が’x1とx2`にどのように依存するかが決まる。\n\nx7$backward()\n\nこの呼び出しにより、x1とx2の$gradフィールドが埋まる。\n\nx1$grad\n\ntorch_tensor\n 0.8000\n[ CPUFloatType{1} ]\n\nx2$grad\n\ntorch_tensor\n 0.8000\n[ CPUFloatType{1} ]\n\n\nこれらは、それぞれx7のx1とx2に関する偏微分である。 上記の手計算を確認すると、どちらも0.8つまり0.4にテンソル値2及び2をかけたものになっている。\nすでに述べた、端から端の微分を積み上げるのに必要な積算過程はどうなっているのか。 積み上げられるに従って端から端までの微分を「追跡」することはできるのだろうか。 例えば、最終出力がどのようにx3に依存しているか見ることはできるだろうか。\n\nx3$grad\n\ntorch_tensor\n[ Tensor (undefined) ]\n\n\nこのフィールドは埋まっていないようである。 実は、これらを計算することは必要だが、torchは不要になったら中間集計を捨て、メモリを節約する。 しかしながら、保存するretarin_grad = TRUEを渡して保存を指示することも可能だ。\n\nx3 &lt;- x1$square()\nx3$retain_grad()\n\nx5 &lt;- x3 * 0.2\nx5$retain_grad()\n\nx4 &lt;- x2$square()\nx4$retain_grad()\n\nx6 &lt;- x4 * 0.2\nx6$retain_grad()\n\nx7 &lt;- x5 + x6 - 5\nx7$backward()\n\nそれでは、x3のgradフィールドが埋まっているか確認してみよう。\n\nx3$grad\n\ntorch_tensor\n 0.2000\n[ CPUFloatType{1} ]\n\n\nx4、x5、x6についても同様だ。\n\nx4$grad\n\ntorch_tensor\n 0.2000\n[ CPUFloatType{1} ]\n\nx5$grad\n\ntorch_tensor\n 1\n[ CPUFloatType{1} ]\n\nx6$grad\n\ntorch_tensor\n 1\n[ CPUFloatType{1} ]\n\n\nもう一つ気になることがある。 勾配の蓄積過程を「実行中の勾配」の観点から理解したが、蓄積を進めるのに必要な個々の微分はどのように計算されるのか。 例えばx3$gradが示しているのは出力が中間状態x3にどのように依存しているかであるが、ここから実際の入力ノードであるx1にどのように到達するのか。\nこの面についても、確認できる。 順伝播でtorchはすべきことを書き残しておいて、後で個々の微分を計算する。 この「レシピ」はテンソルのgrad_fnフィールドに格納される。 これがx3に対してx1への「失われたつながり」を追加する。\n\nx3$grad_fn\n\nPowBackward0\n\n\nx4、x5、x6についても同様。\n\nx4$grad_fn\n\nPowBackward0\n\nx5$grad_fn\n\nMulBackward1\n\nx6$grad_fn\n\nMulBackward1\n\n\nこれでおしまい。 この節では、torchがどのように微分を計算するかを見た上で、それをどのように行っているかの概要を示した。 ここで、自動微分を応用した最初の二つの課題に取り組む準備が整った。",
    "crumbs": [
      "torchに慣れる",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>自動微分</span>"
    ]
  },
  {
    "objectID": "optim1.html",
    "href": "optim1.html",
    "title": "5  autogradを使った函数の最小化",
    "section": "",
    "text": "5.1 最適化の古典\n最適化研究において、ローゼンブロック函数 は古典である。 この函数は二つの変数をとり、(1, 1)で最小となる。 等値線を眺めると、最小は伸びた細い谷の中にあることが分かる。\n函数の定義は次の通りだ。 aとbは自由に定めてよいパラメタだが、よく使われる値を用いる。\na &lt;- 1\nb &lt;- 5\n\nrosenbrock &lt;- function(x) {\n  x1 &lt;- x[1]\n  x2 &lt;- x[2]\n  (a - x1)^2 + b * (x2 - x1^2)^2\n}",
    "crumbs": [
      "torchに慣れる",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>*autograd*を使った函数の最小化</span>"
    ]
  },
  {
    "objectID": "optim1.html#最適化の古典",
    "href": "optim1.html#最適化の古典",
    "title": "5  autogradを使った函数の最小化",
    "section": "",
    "text": "Figure 5.1: ローゼンブロック函数",
    "crumbs": [
      "torchに慣れる",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>*autograd*を使った函数の最小化</span>"
    ]
  },
  {
    "objectID": "optim1.html#最小化を白紙から",
    "href": "optim1.html#最小化を白紙から",
    "title": "5  autogradを使った函数の最小化",
    "section": "5.2 最小化を白紙から",
    "text": "5.2 最小化を白紙から\nシナリオは次の通り。 与えられた点(x1, x2)から出発し、ローゼンブロック函数が最小になる場所を見つける。\n前の章で説明した方法に従い、現在の位置における函数の勾配を計算し、それを使って逆方向にに進む。 どれくらい遠くまで行けばよいかは分からない。 大きく進みすぎると、簡単に行き過ぎてしまう。 （等値線図を再度確認すると最小値のの西または東の急な崖に立っていると、これがすぐに生じることが分かる。）\nつまり、最良の方法は反復して進むことで、妥当な幅を取り、毎回勾配を再評価することだ。\nまとめると、最適化の手順は次のようになる。\nlibrary(torch)\n\n# これはまだ正しい手順ではない!\n\nfor (i in 1:num_iterations) {\n  \n  # 函数を呼び現在のパラメタ値を渡す。\n  value &lt;- rosenbrock(x)\n  \n  # パラメタについての勾配を計算する。\n  value$backward()\n  \n  # 手動でパラメタを更新し、勾配に比例した一部を引く。\n  # ここはまだ正しくない。\n  x$sub_(lr * x$grad)\n}\n書かれている通り、コード片は考えを示したもので、（まだ）正しくない。 また、いくつかの必要なものが欠けている。 テンソルxも変数lrやnum_iterationsも定義されていない。 まず、これらを準備しよう。 学習率lrは毎回引く勾配に比例した一部で、num_iterationsは反復する回数である。 これらは実験パラメタである。\nlr &lt;- 0.01\n\nnum_iterations &lt;- 1000\nxは最適化するパラメタ、つまり函数の入力であり、最適化の最後に可能な限り最小の函数値に近い値を与える位置であることが望まれる。 このテンソルについて函数の微分を計算するので、requires_grad = TRUEをつけて作る必要がある。\nx &lt;- torch_tensor(c(-1, 1), requires_grad = TRUE)\n初期位置(-1, 1)は任意に選択した。 さて、残っているのは最適化ループを少し修正することだ。 autograd がxについて有効化されていると、torchはこのテンソルに対して行われるすべての演算を記録する。 そのためbackward()を呼ぶたびに、すべての必要な微分を計算しようとすることになる。 しかし、勾配の一部を引くときは、微分を今朝さんする必要はない。 torchにこれを記録しないように指示するために、with_no_grad()を囲む。\nここで説明しておかなければならないことがある。 既定でtorchはgradフィールドに格納された勾配を筑西する。 新しい計算をするたびにgrad$zero_()を使ってゼロに消去する必要がある。\nこれらを考慮すると、パラメタの更新は次のように書ける。\nwith_no_grad({\n  x$sub_(lr * x$grad)\n  x$grad$zer_()\n})\n完成したコードは次のようになる。 ログをとる文を追加して何が起きているか分かるようにしてある。\n\nlibrary(torch)\n\nnum_iterations &lt;- 1000\n\nlr &lt;- 0.01\nx &lt;- torch_tensor(c(-1, 1), requires_grad = TRUE)\n\nfor (i in 1:num_iterations) {\n  if (i %% 100 == 0) cat(\"Iteration: \", i, \"\\n\")\n  \n  value &lt;- rosenbrock(x)\n  if (i %% 100 == 0) {\n    cat(\"Value is : \", as.numeric(value), \"\\n\")\n  }\n  \n  value$backward()\n  if (i %% 100 == 0 ) {\n    cat(\"Gradient is : \", as.matrix(x$grad), \"\\n\")\n  }\n  \n  with_no_grad({\n    x$sub_(lr * x$grad)\n    x$grad$zero_() \n  })\n}\n\nIteration:  100 \nValue is :  0.3502924 \nGradient is :  -0.667685 -0.5771312 \nIteration:  200 \nValue is :  0.07398106 \nGradient is :  -0.1603189 -0.2532476 \nIteration:  300 \nValue is :  0.02483024 \nGradient is :  -0.07679074 -0.1373911 \nIteration:  400 \nValue is :  0.009619333 \nGradient is :  -0.04347242 -0.08254051 \nIteration:  500 \nValue is :  0.003990697 \nGradient is :  -0.02652063 -0.05206227 \nIteration:  600 \nValue is :  0.001719962 \nGradient is :  -0.01683905 -0.03373682 \nIteration:  700 \nValue is :  0.0007584976 \nGradient is :  -0.01095017 -0.02221584 \nIteration:  800 \nValue is :  0.0003393509 \nGradient is :  -0.007221781 -0.01477957 \nIteration:  900 \nValue is :  0.0001532408 \nGradient is :  -0.004811743 -0.009894371 \nIteration:  1000 \nValue is :  6.962555e-05 \nGradient is :  -0.003222887 -0.006653666 \n\n\n1000回の反復後、函数値は0.0001よりも小さくなった。 対応する(x1,x2)の位置はどこになったか。\n\nx\n\ntorch_tensor\n 0.9918\n 0.9830\n[ CPUFloatType{2} ][ requires_grad = TRUE ]\n\n\nこれは真の最小(1,1)にかなり近い。 気が向いたら、学習率がどのような違いを生じるか試してみよう。 例えば、0.001と0.1をそれぞれ使ってみるとよい。\n次の章では、白紙からニューラルネットワークを構築する。 そこで最小化するのは 損失函数 、つまり回帰問題から現れる平均二乗誤差である。",
    "crumbs": [
      "torchに慣れる",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>*autograd*を使った函数の最小化</span>"
    ]
  },
  {
    "objectID": "network1.html",
    "href": "network1.html",
    "title": "6  ニューラルネットワークを白紙から",
    "section": "",
    "text": "6.1 ネットワークの考え方\n簡単にいうと、ネットワークは入力から出力への関数だ。 適切な函数が求めるものだ。\nこれを決めるには、会期として線型回帰を考えてみよう。 線型回帰がしているのは、掛け算と足し算だ。 独立変数一つ一つに対して、これに掛ける係数がある。 それから、バイアス と呼ばれる項を末尾に加える。 （二次元では、回帰係数とバイアスは回帰直線の傾きとy切片である。）\nこれらを考慮すると、乗算と加算はテンソルでできることで、テンソルはこれらの演算のためにあると言ってもいいくらいだ。 例として、入力が百個の観測からなり、特徴量がそれぞれ三つあるものを示す。\nlibrary(torch)\n\nx &lt;- torch_randn(100, 3)\nx$size()\n\n[1] 100   3\nxに掛ける特徴量ごとの係数を格納するために、特徴量の数である長さ3の列ベクトルが必要だ。 あるいは、この後すぐ行う修正に備えて、列の長さが三の行列にしてもよい。 つまり、三行を持つ行列である。 列はいくつ必要か。 単一の特徴量を予測したいとすれば、行列は大きさ3 x 1となる。\nよさそうな候補を乱数で初期化する。 テンソルはrequires_grad = TRUEをつけて作成されていることに留意する。 この変数はネットワークに学習てもらいたいパラメタを表しているからだ。\nw &lt;- torch_randn(3, 1, requires_grad = TRUE)\nバイアステンソルは大きさ1 x 1となる。\nb &lt;- torch_zeros(1, 1, requires_grad = TRUE)\nこれで、データに重みwをかけ、バイアスbを加えて「予測」を得ることができる。\ny &lt;- x$matmul(w) + b\nprint(y, n = 10)\n\ntorch_tensor\n 0.0396\n-0.8456\n-0.0511\n-0.6159\n-0.5215\n-0.8483\n 0.1778\n 0.0294\n-0.3373\n 0.4959\n... [the output was truncated (use n=-1 to disable)]\n[ CPUFloatType{100,1} ][ grad_fn = &lt;AddBackward0&gt; ]\n数学の表記では、ここでは次の函数を実装した。\n\\[\nf(\\mathbf{X}) = \\mathbf{X}\\mathbf{W} + \\mathbf{b}\n\\]\nこれのどこがニューラルネットワークなのか。",
    "crumbs": [
      "torchに慣れる",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>ニューラルネットワークを白紙から</span>"
    ]
  },
  {
    "objectID": "network1.html#ネットワークの層",
    "href": "network1.html#ネットワークの層",
    "title": "6  ニューラルネットワークを白紙から",
    "section": "6.2 ネットワークの層",
    "text": "6.2 ネットワークの層\nニューラルネットワークの用語に戻れば、ここでしたのは単層のネットワーク、出力層の動作の原型である。 単層ネットワークは構築したい類とはとてもいえない。 単に線型内挿すれば済むのに、なぜネットワークを作るのか。 実際、ニューラルネットワークの特徴は、（理論的に）無数の層を連鎖できることになある。 もちろん出力層以外は「隠れ」層と呼ばれるが。深層学習フレームワークを使う上では全く 隠れ ている訳ではない。\n例えば、隠れ層が一つあるネットワークを作りたいとしよう。 その大きさ、つまり層が持つユニットの数はネットワークの力を決める重要な要因になる。 この数は作成する重み行列の大きさに反映される。 八つのユニットを持つ層には八つの列を持つ行列が必要である。\nw1 &lt;- torch_randn(3, 8, requires_grad = TRUE)\n各ユニットにはそれぞれバイアス値もある。\nb1 = torch_zeros(1, 8, requires_grad = TRUE)\n以前見たように、隠れ層は受け取った入力に重みを掛けてバイアスを加える。 つまり、上に示した函数\\(f\\)を適用する。 そして、別の函数を適用する。 この函数は隠れそうから入力を受け取り、最終出力を生成する。 結局、ここで行われているのは函数の合成である。 二番目の函数\\(g\\)を呼び出すと、全体の変換は\\(g(f(\\mathbf{X}))\\)つまり\\(g\\circ f\\)となる。\n上述の単層構造に類似した出力を\\(g\\)がするには、その重み行列は八つの列の隠れ層を取り、単一の列にしなければならない。 つまり、w2 は次のようになる。\nw2 &lt;- torch_randn(8, 1, requires_grad = TRUE)\nバイアスb2はb1のように単一の値である。\nb2 &lt;- torch_randn(1, 1, requires_grad = TRUE)\nもちろん、単一の隠れ層に止める理由はなく、仕組みを完成させたら、自由にコードをいじってほしい。 でも最初に、追加しなければならない部品がいくつかある。 その一つは、今の構造では函数を連鎖、あるいは合成しているのはよいが、これらの函数がしているのは加算と乗算であり、線型である。 しかし、ニューラルネットワークの力は通常 非線型性 にある。なぜか。",
    "crumbs": [
      "torchに慣れる",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>ニューラルネットワークを白紙から</span>"
    ]
  },
  {
    "objectID": "network1.html#活性化函数",
    "href": "network1.html#活性化函数",
    "title": "6  ニューラルネットワークを白紙から",
    "section": "6.3 活性化函数",
    "text": "6.3 活性化函数\nここで、三つの層からなるネットワークがあったとして、各層では入力に重みを掛けただけだとする。 （バイアス項を考慮することで変わるものはないにもないが、例がややこしくなるだけなので、省略する。）\nこのネットワークは行列積の連鎖 \\(f(\\mathbf{X}) = ((\\mathbf{XW}_1)\\mathbf{W}_2)\\mathbf{W}_3\\) になる。 さて、この式を変形するとすべての重み行列を掛け合わせてから\\(\\mathbf{X}\\)に作用させ\\(f(\\mathbf{X}) = \\mathbf{X}(\\mathbf{W}_1\\mathbf{W}_2\\mathbf{W}_3)\\)と書くことができる。 つまり三つの層のネットワークは単層のものに簡略化され、\\(f(\\mathbf{X}) = \\mathbf{XW}_4\\)となる。 こうなると、深層ニューラルネットワークの利点がすべて失われてしまう。\nここで活性化函数、時に「非線型性」が登場する。 これは非線型演算を導入するもので、行列演算でモデル化することはできない。 歴史的には典型的な活性化函数は シグモイド であり、現在でも極めて重要である。 その本質的な作用は入力を0と1との間に圧縮して確率と解釈できる量を与える。 回帰では、これが求めるものではなく、ほとんどの隠れ層についても同様だ。\n代わりに、ネットワークの中で最も利用されている活性化函数は ReLU、Rectified Linear Unit（正規化線型函数）と呼ばれるものだ。 名前は長いが単に全ての負の値を0するだけだ。 torchではrelu()でこれができる。\n\nt &lt;- torch_tensor(c(-2, 1, 5, -7))\n\nなぜこれが非線型なのか。 線型である規準の一つは、二つの入力に対し先に加えてから変換しても、先に個々の入力を変換してから加えても結果が同じになることだ。 ReLUではそのようにはならない。\n\nt1 &lt;- torch_tensor(c(1, 2, 3))\nt2 &lt;- torch_tensor(c(1, -2, 3))\n\nt1$add(t2)$relu()\n\ntorch_tensor\n 2\n 0\n 6\n[ CPUFloatType{3} ]\n\n\n\nt1_clamped &lt;- t1$relu()\nt2_clamped &lt;- t2$relu()\n\nt1_clamped$add(t2_clamped)\n\ntorch_tensor\n 2\n 2\n 6\n[ CPUFloatType{3} ]\n\n\n結果は同じではない。\nこれまでをまとめると、層を重ねて活性化函数を作用されることを説明した。 あと一つ概念を示してからネットワークを完成される。 その概念とは損失函数だ。",
    "crumbs": [
      "torchに慣れる",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>ニューラルネットワークを白紙から</span>"
    ]
  },
  {
    "objectID": "network1.html#損失函数",
    "href": "network1.html#損失函数",
    "title": "6  ニューラルネットワークを白紙から",
    "section": "6.4 損失函数",
    "text": "6.4 損失函数\n抽象的にいえば、損失とは目的からどれくらい離れているかという尺度だ。 函数を最小化するとき、前の章で行ったように、これは現在の函数値と取りうる最小の値との差である。 ニューラルネットワークでは、目的に適合している限り損失函数を自由に選ぶことができる。 回帰問題では、平均二乗誤差（MSE: mean square error）がよく用いられるが、それには限らない。 平均絶対誤差を代わりに用いるべきこともあるだろう。\ntorchでは、平均二乗誤差は一行で書ける。\n\ny &lt;- torch_randn(5)\ny_pred &lt;- y + 0.01\n\nloss &lt;- (y_pred - y)$pow(2)$mean()\n\nloss\n\ntorch_tensor\n9.99998e-05\n[ CPUFloatType{} ]\n\n\n損失函数が決まれば、重みの更新は勾配に比例した一部を引くことでできる。 やり方は既に前の章で見たが、すぐにまた行うことになる。\nそれでは説明した部品を集めて組み立てよう。",
    "crumbs": [
      "torchに慣れる",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>ニューラルネットワークを白紙から</span>"
    ]
  },
  {
    "objectID": "network1.html#ネットワークの実装",
    "href": "network1.html#ネットワークの実装",
    "title": "6  ニューラルネットワークを白紙から",
    "section": "6.5 ネットワークの実装",
    "text": "6.5 ネットワークの実装\n実装は三つの部分に分かれる。 こうしておくと、後でtorchの高レベルの機能を利用してそれぞれの部分を改訂する際に、カプセル化やモジュール化が行われる部分が分かりやすい。\n\n6.5.1 ランダムデータの生成\n例として使うデータは百個の観測からなる。 入力xは三つの特徴量を持つ。 目的yは一つの値で、yはxから生成されるが、ノイズが加えられる。\n\nlibrary(torch)\n\n# 入力次元（入力の特徴量の数）\nd_in &lt;- 3\n# 訓練集合の観測数\nn &lt;- 100\n\nx &lt;- torch_randn(n, d_in)\ncoefs &lt;- c(0.2, -1.3, -0.5)\ny &lt;- x$matmul(coefs)$unsqueeze(2) + torch_randn(n, 1)\n\n\n\n6.5.2 ネットワークの構築\nネットワークは隠れ層と出力層の二層とする。 つまり二つの重み行列と二つのバイアステンソルが必要である。 特に理由はないが、隠れ層には三十二ユニット配置する。\n\n# 隠れ層の次元\nd_hidden &lt;- 32\n# 出力次元（予測される特徴量の数）\nd_out &lt;- 1\n\n# 入力を隠れ層に結合する重み\nw1 &lt;- torch_randn(d_in, d_hidden, requires_grad = TRUE)\n# 隠れ層を出力に結合する重み\nw2 &lt;- torch_randn(d_hidden, d_out, requires_grad = TRUE)\n\n# 隠れ層のバイアス\nb1 &lt;- torch_zeros(1, d_hidden, requires_grad = TRUE)\n# 出力層のバイアス\nb2 &lt;- torch_zeros(1, d_out, requires_grad = TRUE)\n\n現在の値、乱数初期化の結果は、重みとバイアスは有用ではない。 ネットワークを訓練する時が来た。\n\n\n6.5.3 ネットワークの訓練\nネットワークの訓練は入力を層に伝播させ、損失を計算し、パラメタ（重みとバイアス）を調整して、予測を向上するようにする事である。 性能が十分（実際の応用では、非常に注意深く定義する必要がある）と思われるまで、これらの計算を繰り返す。 技術的には、これらの手順を反復して適用する各回を エポック と呼ぶ。\n函数の最小化のように、適切な学習率（差し引く勾配の比率）は実験的によって決める。\n以下に示す訓練ループを見ると、必然的に四つの部分に分かれることが分かる。\n\n順伝播してネットワークの予測を得る（一行に書くのが好みでないなら、分けて書いてもよい）。\n損失を計算する（これも一行で、いくらかのログ出力を追加しただけだ）。\nautograd に損失のバラメタに対する勾配を計算させる。\nパラメタを適切に更新する（ここでも全ての演算をwith_no_grad()で囲み、gradフィールドを反復ごとにゼロにしている）。\n\n\nlearning_rate &lt;- 1e-4\n\n### 訓練ループ----------------------------------------\n\nfor (t in 1:200) {\n  \n  ### ------- 順伝播 -------\n  \n  y_pred &lt;- x$mm(w1)$add(b1)$relu()$mm(w2)$add(b2)\n  \n  ### ------- 損失の計算 -------\n  loss &lt;- (y_pred - y)$pow(2)$mean()\n  if (t %% 10 == 0)\n    cat(\"Epoch: \", t, \"   Loss: \", loss$item(), \"\\n\")\n  \n  ### ------- 逆伝播 -------\n  \n  # `requires_grad = TRUE がついた\n  # 全てのデンソルについて損失の勾配を計算\n  loss$backward()\n  \n  ### ------- 重みの更新 -------\n  \n  # この部分は自動勾配計算のために記録したくない部分なので\n  # with_no_grad()で囲む。\n  \n  with_no_grad({\n    w1 &lt;- w1$sub_(learning_rate * w1$grad)\n    w2 &lt;- w2$sub_(learning_rate * w2$grad)\n    b1 &lt;- b1$sub_(learning_rate * b1$grad)\n    b2 &lt;- b2$sub_(learning_rate * b2$grad)\n    \n    # 伝播ごとにゼロにする。\n    # そうしないと蓄積してしまう。\n    w1$grad$zero_()\n    w2$grad$zero_()\n    b1$grad$zero_()\n    b2$grad$zero_()\n  })\n\n}\n\nEpoch:  10    Loss:  32.97625 \nEpoch:  20    Loss:  30.58289 \nEpoch:  30    Loss:  28.40753 \nEpoch:  40    Loss:  26.42452 \nEpoch:  50    Loss:  24.61633 \nEpoch:  60    Loss:  22.9623 \nEpoch:  70    Loss:  21.44905 \nEpoch:  80    Loss:  20.06274 \nEpoch:  90    Loss:  18.79105 \nEpoch:  100    Loss:  17.62292 \nEpoch:  110    Loss:  16.54894 \nEpoch:  120    Loss:  15.56187 \nEpoch:  130    Loss:  14.65133 \nEpoch:  140    Loss:  13.80992 \nEpoch:  150    Loss:  13.03385 \nEpoch:  160    Loss:  12.3165 \nEpoch:  170    Loss:  11.6521 \nEpoch:  180    Loss:  11.03611 \nEpoch:  190    Loss:  10.46439 \nEpoch:  200    Loss:  9.933251 \n\n\n損失は最初急速に減少し、その後それほど速く減少なくなる。 この例はすばらしい性能を示すために作られたのでなく、わずかな行のコードで「本物の」ニューラルネットワークが構築できることを示すことが意図である。\n層や、損失、パラメタ更新はまだかなら粗削りで、（文字通り）単なるテンソルである。 このような小さなネットワークには問題だが、より複雑な設計ではすぐに面倒になる。 以下の二つの章では、重みとバイアスをネットワークに抽象化し、自作の損失函数を組込のものに取り替え、冗長なパラメタ更新部分を取り除く。",
    "crumbs": [
      "torchに慣れる",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>ニューラルネットワークを白紙から</span>"
    ]
  },
  {
    "objectID": "modules.html",
    "href": "modules.html",
    "title": "7  モジュール",
    "section": "",
    "text": "7.1 組込のnn_moudle()\ntorchでは、線型層はnn_linear()で作る。 nn_linear()は、in_featuresとout_featuresの（最低）二つの引数が必要である。 入力データに観測が50あり、それぞれ五つの特徴量がある場合、大きさは50 x 5となる。 潜在層には、16のユニットを置く。 この場合、in_featuresは5、out_featuresは16である。 （自分で重み行列を作る場合、同じ5と16が行と列の数である。）\nlibrary(torch)\nl &lt;- nn_linear(in_features = 5, out_features = 16)\n一度作られれば、モジュールのパラメタの情報は簡単に得られる。\nl\n\nAn `nn_module` containing 96 parameters.\n\n── Parameters ──────────────────────────────────────────────────────────────────\n• weight: Float [1:16, 1:5]\n• bias: Float [1:16]\nカプセル化されていても、重みとバイアステンソルを確認することができる。\nl$weight\n\ntorch_tensor\n-0.4092  0.1703 -0.4097 -0.2516 -0.2588\n 0.4400  0.2235 -0.2079  0.2655 -0.2361\n-0.3803  0.0923  0.0338 -0.0634 -0.2811\n 0.4434 -0.3469  0.1170 -0.0147  0.1219\n 0.0957 -0.1450  0.0452  0.0765 -0.2608\n-0.4279  0.0293 -0.3494 -0.0524 -0.1841\n-0.1750 -0.3164  0.2479 -0.0122  0.1207\n 0.2948 -0.1840  0.2093  0.3891  0.2946\n-0.0275 -0.3332 -0.0515  0.4374  0.3864\n-0.3170 -0.2871 -0.0459  0.0959 -0.1508\n 0.1369 -0.4022  0.1669 -0.2082  0.2024\n-0.3099  0.0968 -0.3867  0.2763  0.4359\n-0.3716 -0.3656  0.3508  0.1329 -0.4383\n 0.2252 -0.0987  0.0262  0.2400  0.1650\n 0.3479 -0.0648  0.4347  0.0286  0.3225\n 0.0719  0.0617  0.3790 -0.0240  0.2522\n[ CPUFloatType{16,5} ][ requires_grad = TRUE ]\nl$bias\n\ntorch_tensor\n-0.4203\n-0.3574\n 0.3654\n-0.0573\n-0.1818\n 0.3930\n-0.2191\n-0.0698\n-0.1121\n-0.4159\n 0.3902\n 0.2673\n 0.4144\n 0.2159\n-0.2861\n-0.3794\n[ CPUFloatType{16} ][ requires_grad = TRUE ]\nこの時点で、ちょっと立ち止まってほしい。 torchが返した重み行列の大きさは16 x 5で、白紙からコードを書いたときの5 x 16ではない。 これは基礎となるC++実装libtorchに由来する。 性能のため、libtorchの線型モジュールは重みとバイアスを転置で格納している。 Rからは、この点を指摘しておくことくらいしかできない。 混乱が軽減されることを望む。\n続けよう。 このモジュールにデータを適用するには函数のように「呼び出す」だけだ。\nx &lt;- torch_randn(50, 5)\noutput &lt;- l(x)\noutput$size()\n\n[1] 50 16\nこれが順伝播だ。 勾配計算はどうするのか。 以前は、勾配計算の「入力」として必要なテンソルを作るとき、torchに明示的にrequires_grad = TRUEを渡す必要があった。 組込nn_module()ではその必要はない。 すぐにoutputがbackward()でどのような計算をすべきか調べることができる。\noutput$grad_fn\n\nAddmmBackward0\n確認のため、outputに基づいて、適当な損失を計算して、backward()を読んでみよう。 線型モジュールのweightテンソルには埋められたgradフィールドがあることが分かる。\nloss &lt;- output$mean()\nloss$backward()\nl$weight$grad\n\ntorch_tensor\n0.01 *\n-1.4562 -1.1237  1.7362 -1.7758  0.1989\n -1.4562 -1.1237  1.7362 -1.7758  0.1989\n -1.4562 -1.1237  1.7362 -1.7758  0.1989\n -1.4562 -1.1237  1.7362 -1.7758  0.1989\n -1.4562 -1.1237  1.7362 -1.7758  0.1989\n -1.4562 -1.1237  1.7362 -1.7758  0.1989\n -1.4562 -1.1237  1.7362 -1.7758  0.1989\n -1.4562 -1.1237  1.7362 -1.7758  0.1989\n -1.4562 -1.1237  1.7362 -1.7758  0.1989\n -1.4562 -1.1237  1.7362 -1.7758  0.1989\n -1.4562 -1.1237  1.7362 -1.7758  0.1989\n -1.4562 -1.1237  1.7362 -1.7758  0.1989\n -1.4562 -1.1237  1.7362 -1.7758  0.1989\n -1.4562 -1.1237  1.7362 -1.7758  0.1989\n -1.4562 -1.1237  1.7362 -1.7758  0.1989\n -1.4562 -1.1237  1.7362 -1.7758  0.1989\n[ CPUFloatType{16,5} ]\nつまり、nn_moduleを使うと、torchは自動的に勾配計算が必要だとみなされる。\nnn_linearは簡単に見えるが、ほとんど全てのモデル構成において必須の要素だ。",
    "crumbs": [
      "torchに慣れる",
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>モジュール</span>"
    ]
  },
  {
    "objectID": "modules.html#組込のnn_moudle",
    "href": "modules.html#組込のnn_moudle",
    "title": "7  モジュール",
    "section": "",
    "text": "nn_conv1d()、nn_conv2d()、およびnn_conv3d()、いわゆる畳み込み層は入力要素に対するフィルタを異なる次元で適用する。\nnn_lstm()とnn_gru()は状態を引き継ぐ再帰層。\nnn_embedding()は高次元の質的データにつ分かれる。\nその他多数",
    "crumbs": [
      "torchに慣れる",
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>モジュール</span>"
    ]
  },
  {
    "objectID": "modules.html#モデルの構築",
    "href": "modules.html#モデルの構築",
    "title": "7  モジュール",
    "section": "7.2 モデルの構築",
    "text": "7.2 モデルの構築\n組込のnn_module()は普通の呼び方では層だが、どのようにモデルに組み上げるのか。 「工場函数」nn_module()を使って、モデルを任意の複雑さで定義できる。 でも、必ずしもそうする必要はない。\n\n7.2.1 層の列としてのモデル: nn_sequential()\nモデルが単に層を伝播するだけであれば、モデルを作るときにnn_sequential()が使える。 線型層だけからなるモデルは多層パーセプトロン（MPL: Multi-Layer Perceptron）として知られている。\n\nmlp &lt;- nn_sequential(\n  nn_linear(10, 32),\n  nn_relu(),\n  nn_linear(32, 64),\n  nn_relu(),\n  nn_linear(64, 1)\n)\n\n関係する層を詳しく見てみよう。 ReLU活性化を実装した函数をであった。 （nnf_のfは汎函数であることを示す。） 以下はnn_reluはnn_linear()と同様でモジュール、つまりオブジェクトで、引数は全てモジュールでなければならない。\n組込モジュール同様、このモデルをデータに適用するには呼び出せばよい。\n\nmlp(torch_randn(5, 10))\n\ntorch_tensor\n-0.1822\n-0.1332\n-0.0302\n-0.1011\n-0.0562\n[ CPUFloatType{5,1} ][ grad_fn = &lt;AddmmBackward0&gt; ]\n\n\n一回の呼び出しによりネットワークを通じた順伝播が始動した。 同様に、backward()を呼び出せ全ての層を通じて逆伝播される。\n\n\n7.2.2 独自処理のモデル\n既に暗示されているように、ここがnn_moduleの使いどころだ。\nnn_module|()は独自に作成されたR6オブジェクトに対するコンストラクタを作る。 以下、my_linear()はそのようなコンストラクタだ。 呼び出させれると、組込のnn_linear()に似た線型モジュールを返す。\nコンストラクタの定義の中で、二つのメソッドが実装されなければならない。initialize()とforward()である。 initialize()はモジュールのオブジェクトフィールドを作る。 すなわちそれが持つオブジェクトまたは値でどのメソッドの中からも見える。 forward()はモジュールが入力があったときの動作を定義する。\n\nmy_linear &lt;- nn_module(\n  initialize = function(in_features, out_features) {\n    self$w &lt;- nn_parameter(torch_randn(\n      in_features, out_features\n    ))\n    self$b &lt;- nn_parameter(torch_zeros(out_features))\n  },\n  forward = function(input) {\n    input$mm(self$w) + self$b\n  }\n)\n\nnn_parameter()の使い方を見てほしい。 nn_parameter()は渡されたテンソルかモジュールの パラメタ として登録されていることを確認する、つまり逆伝播されるのが既定だ。\n新たに定義されたモジュールのインスタンスを作るには、コンストラクタを呼び出す。\n\nl &lt;- my_linear(7, 1)\nl\n\nAn `nn_module` containing 8 parameters.\n\n── Parameters ──────────────────────────────────────────────────────────────────\n• w: Float [1:7, 1:1]\n• b: Float [1:1]\n\n\nこの例には、モジュールを定義するために必要な独自の計算手順はないが、ここではどんな利用形態にも適用できる雛型である。 後に、より複雑なinitialize()とforward()を検討したが、モジュールに定義される追加のメソッドを示す。 基本的な仕組みは一緒だ。\nここ手では、前の章でモジュールを使ったニューラルネットワークを書き換えることができると感じるかもしれない。 自由に取り組んでもよいし、最適化手法と組込損失函数を学ぶ次の章まで待ってもよい。 それが済んだら、函数最小化と回帰ネットワークの二つの例に戻ることができる。 そして、torchにより自作した余計なものを取り除くことができる。",
    "crumbs": [
      "torchに慣れる",
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>モジュール</span>"
    ]
  },
  {
    "objectID": "optimizers.html",
    "href": "optimizers.html",
    "title": "8  最適化器",
    "section": "",
    "text": "8.1 何のための最適化器か\nこの質問には、主に二つの答えがある。 一つは技術的なものだ。 最初のニューラルネットワークのコードをどのように書いたか思い出すと、次のように進めていたことが分かる。\n最後の部分を再掲する。\nこの例は小さなネットワークだったが、このような計算手順を数十、数百層を持つ構造についてコードを書かなければならないとしたら大変だ。 当然、それは深層学習フレームワークの開発者がユーザにしてほしいことではない。 だから、重みの更新は専用のオブジェクト、当該の最適化器が担当する。\nつまり、技術面の答えは使い勝手と利便性に関係する。 しかし、他のことも関係している。 以上の方法では、良好な学習率は試行錯誤により決めるしかない。 そしておそらく、最適な学習率が訓練過程を通じて一定であることもない。 ありがたいことに、これまでのたくさんの研究で確立した更新方法がいくつも存在する。 これらの方法は、通常演算の間の状態に依存する。 これが、torchにおいて最適化器がモジュールのようにオブジェクトである、もう一つの理由だ。\nこれらの方法を詳しく見る前に、手動の重み更新過程を最適化器を使った版に置き換える方法を示す。",
    "crumbs": [
      "torchに慣れる",
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>最適化器</span>"
    ]
  },
  {
    "objectID": "optimizers.html#何のための最適化器か",
    "href": "optimizers.html#何のための最適化器か",
    "title": "8  最適化器",
    "section": "",
    "text": "予測（順伝播）を計算し、\n損失を算出し、\nautograd を使って（loss$backward()を呼びだし）偏微分を計算して、\nバラメタを更新するため、勾配の一定の割合をそれぞれ引く。\n\n\nlibrary(torch)\n\n# requires_grad = TRUEがついた\n# 全てのテンソルに関して損失の勾配を計算\nloss$backward()\n\n### -------- 重みを更新 --------\n\n# この部分は自動勾配計算に記録したくないので、\n# `with_no_grad()`で包む。\nwith_no_grad({\n  w1 = w1$sub_(learning_rate * w1$grad)\n  w2 = w2$sub_(learning_rate * w2$grad)\n  b1 = b1$sub_(learning_rate * b1$grad)\n  b2 = b2$sub_(learning_rate * b2$grad)\n  \n  # 毎回勾配を0にする。\n  # さもないと積み上がってしまう。\n  w1$grad$zero_()\n  w2$grad$zero_()\n  b1$grad$zero_()\n  b2$grad$zero_()\n})",
    "crumbs": [
      "torchに慣れる",
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>最適化器</span>"
    ]
  },
  {
    "objectID": "optimizers.html#torch組込最適化器の利用",
    "href": "optimizers.html#torch組込最適化器の利用",
    "title": "8  最適化器",
    "section": "8.2 torch組込最適化器の利用",
    "text": "8.2 torch組込最適化器の利用\n最適化器は何を最適化するか知る必要がある。 ニューラルネットワークの文脈では、それはネットワークのパラメタである。 とは言っても、「モデルのモジュール」と「層のモジュール」に実質的な差はないので、どのように動作するかをnn_linearのような単一の組込モジュールで説明する。\nまず勾配降下最適化器をある線型モジュールのバラメタに対して働くように作る。\n\nlibrary(torch)\n\nl &lt;- nn_linear(10, 2)\n\nopt &lt;- optim_sgd(l$parameters, lr = 0.1)\n\nいつも必要であるを最適化対象のテンソルへの参照に加えて、optim_sgd()は一つだけ任意でないパラメタ学習率lrがあ。\n一度最適化器オプジェクトを作れば、パラメタの更新はstep()を呼び出すことで実行される。 でも変わってないことが一つある。 訓練の反復に亙って勾配が積み上がらないようにしなければならない。 つまり、zero_grad()を呼び出す必要があるが、今度は最適化器オプジェクトに対して呼べばよい。\n以下に示す完全なコードは、上述の手動の手順を置き換えたものだ。\n# requires_grad = TRUEがついた\n# 全てのテンソルに関して損失の勾配を計算\n# ここは変化なし\nloss$bacward()\n\n# 依然逆伝播の前に勾配を0にする必要がある。\n# 今度は最適化器オブジェクトに対してする。\noptimizer$zero_grad()\n\n# 最適化器を使ってモデルパラメタを更新\noptimizer$step\n使いやすくなったことは納得してもらえると思う。 これはすごい改善だ。 ここで、元の質問「何のための最適化器か」に戻り、二つ目の手法面での答えについてもっと議論する。",
    "crumbs": [
      "torchに慣れる",
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>最適化器</span>"
    ]
  },
  {
    "objectID": "optimizers.html#バラメタの更新手法",
    "href": "optimizers.html#バラメタの更新手法",
    "title": "8  最適化器",
    "section": "8.3 バラメタの更新手法",
    "text": "8.3 バラメタの更新手法\nよい学習率を試行錯誤で探すのは大変だ。 それに学習率だけがはっきりしないものではない。 学習率が指定するのは、歩幅の大きさだけだ。 だが、それだけが未解決の問題ではない。\nこれまで、勾配が与える最急降下方向が最良の方向だと仮定してきた。 それはいつも正しいわけではない。 そのため、パラメタ更新の大きさと方向の両方とも不明ということになる。\nありがたいことに、ここ十年間でニューラルネットワークにおける重みの更新に関する研究が大きく進展した。 ここでは、関係する主要な問題について述べ、torchにより提供されている最もよく使われる最適化器のいくつかを位置付ける。\n比較対象となる基準は 勾配降下 あるいは 最急降下 で、このアルゴリズムを函数最適化やニューラルネットワークの訓練を手動で実装するときに用いてきた。 簡単にその指導原理をおさらいしよう。\n\n8.3.1 勾配降下法\n最急降下や確率的勾配降下法（SGD: stochastic gradient descent）しても知られている。 勾配は偏微分のベクトルで、各入力特徴量に対して一つの要素がある。 これは、関数が最も増加する方向を表す。 その反対方向に進めば、最も速く降下できる。 そうだろうか。\n残念ながら、そう簡単ではない。 取り囲む地形、より技術的には最小化したい函数の等値線に依存する。 説明のだ、二つの状況を考える。\n一つは初めて自動微分を学んだときに出てきたものだ。 その例では二次元の二次函数があった。 そのときは指摘しなかったが、この特定の函数の重要な点は勾配が二つの次元とも同じだった。 そのような条件では、最急降下は最適である。\n確認しよう。 函数は\\(f(x_1,x_2) = 0.2x_1^2 + 0.2x_2^2-5\\)で勾配は\\(\\begin{bmatrix}0.4\\\\0.4\\end{bmatrix}\\)だった。\n例えば点\\((x_1,x_2) = (6, 6)\\)にいるとする。 それぞれの座標軸について、現在の値の0.4倍を引く。 これは学習率1の場合だが、その必要はない。 もし学習列2.5を使えば、一歩で最小に到達できる。 \\((x_1,x_2) = (6 - 2.5 * 0.4 * 6, 6 - 2.5 * 0.4 * 6) = (0, 0)\\). 次の図を見ると、それぞれの場合に何が起きているか分かる。 \nまとめると、このような等方的な函数は二つの方向の分散が等しいので、学習率を正しく決める「だけ」の問題になる。\n次に両方の方向の傾きが大きく異なるとどうなるか、これと比較してみる。\n今度は\\(x_2\\)の係数が\\(x_1\\)の十倍大きく、\\(f(x_1,x_2) = 0.2x_1^2 + 2x_2^2 - 5\\)である。 つまり\\(x_2\\)方向に進むと函数値は大きくなるが、\\(x_1\\)方向にはもっとゆっくり上昇する。 すなわち、勾配降下の間、一つの方向が他の方向よりも大きく進む。\nまた異なる学習率を使うとどうなるか調べる。 以下では三つの異なる設定を比較する。 最も小さい学習率を使うと、最終的に最小に到達するものの、対称な場合よりもかなり遅い。 わずかに大きな学習率を使うと、ジグザクを繰り返して、より影響の大きい\\(x_2\\)が正と負の値の間で振動する。 最後に、学習率をもう少しだけ大きくすることは最悪の効果をもたらす。 函数値は発散し、ジグザクに無限大に大きくなる。\n\n\n\nわずかに異なる学習率を用いた非等方的な放物面上の最急降下\n\n\nこれは非常に説得力がある。 二変数だけのよくある函数でも最急降下は万能からは程遠い。 そして深層学習では、損失函数は もっと 質が悪い。 ここがより洗練されたアルゴリズムが必要になるところである。 最適化器に再度登場願う。\n\n\n8.3.2 問題となること\n概念から見ると、最急降下法の主な改良は、駆動の考え方、つまり解こうとしてい問題により分類できる。\nまず、毎回勾配を再計算する度に、全く新しい方向から始める代わりに、古い方向、技術的には慣性を残したい。 これは上の例で見た非効率なジグザクの防止に役立つはずである。\n次に非対称函数の最小化の例では、本当に全ての変数に対して同じ学習率を使わなければならないのか。 明らかに全ての変数が同程度に変化しないことが明らかであるとき、それらを個別に適切な方法で更新したらよいのではないか。\n三つ目は、過度に影響が大きい特徴量に対して学習率を下げようとした場合にだけ生じる問題に対する修正で、学習が進み、パラメタが更新されることを確実にしたい。\nこれらの考慮すべき点は、最適化アルゴリズムの中でいくつかの古典に示されている。\n\n\n8.3.3 軌道に留まる: 慣性付勾配降下法\n慣性付勾配降下法では、勾配を 直接 重みの更新には使用しない。 代わりに、軌道上の粒子として重みの更新を考える。 粒子は進んでいる方向を維持しようとする、物理で言う慣性が働くが、衝突により向きが変化する。 この「衝突」により 現在 の位置での勾配を考慮するように突かれる。 これらの力学から二段階の更新手順が得られる。\n以下の式で、記号はの選択は物理の類比によるものだ。 \\(\\mathbf{x}\\)は位置で、パラメタ空間で現在いるところ、より簡単には 現在のパラメタ値である。 時間変化は上付添字で表し、\\(\\mathbf{y}^{(k)}\\)は変数\\(\\mathbf{y}\\)の現在時刻\\(k\\)での状態である。 時刻\\(k\\)における瞬間速度は勾配\\(\\mathbf{g}^{(k)}\\)で測る。 位置の更新にはこれを直接用いない。 代わりに各反復で、更新された速度は古い速度に慣性パラメタ\\(m\\)で重み付された値と新たに計算した勾配（学習率で重み付けする）の組み合わせとする。 二段階の最初はこの方法を表している。\n\\[\n\\mathbf{v}^{(k+1)} = m\\mathbf{v}^{(k)} + lr\\mathbf{g}^{(k)}\n\\tag{8.1}\\]\n二段階目は\\(\\mathbf{x}\\)の更新を「折衷」された速度でする。\n\\[\n\\mathbf{x}^{(k+1)} = \\mathbf{x}^{(k)} - \\mathbf{v}^{(k+1)}\n\\tag{8.2}\\]\n物理の類比以外にも、有用かもしれないのは、時系列解析で有名な概念だ。 \\(m\\)と\\(lr\\)の和が1であるように選べば、結果は 指数函数的加重移動平均 となる。 この概念の適用は理解の助けにはなるが、実際は\\(m\\)s \\(lr\\)との和を1にする必要はない。）\nでは、非等方的な放物面に戻り、慣性なしとありのSGDを比較しよう。 後者（明るい曲線）では、\\(lr = 0.5\\)と\\(m = 0.1\\)を用いた。 SGD（暗い曲線）で学習率は上の「よい値」を用いた。 慣性付SDGはかなり少ない歩数で最小に到達するFigure 8.1。\n\n\n\n\n\n\nFigure 8.1: 慣性付SGD（白）と素のSGD（灰）との比較\n\n\n\n\n\n8.3.4 Adagrad\nまだ改善できるだろうか。 用いている例では、一つの特徴量がもう一つよりもかなり速く変化することとが最適化を遅くしている。 異なる学習率をパラメタ毎に使うべきなのは明白だ。 実際、深層学習でよく使われる最適化手法はパラメタ毎に学習率を変えている。 でもどのように決めるのか。\nこの点にアルゴリズムの違いが現れる。 例えば、Adagradは個々のパラメタの更新をその偏微分の（正確には二乗）積算和で割っている。 ここで、「積算」は最初の反復から積み上げる。 「積算変数」\\(s\\)の対象とするパラメタ\\(i\\)、反復回\\(k\\)の値は、次の式で更新する。\n\\[\n\\mathbf{s}_i^{(k)} = \\sum_{j=1}^k(g_i^{(j)})^2\n\\tag{8.3}\\]\n（ところで、数式が苦手なら読み飛ばして構わない。できるだけ言葉で伝えるようにしているので、基本的な情報を失うことはない。）\nここで、個々の変数に対する更新では、勾配の一部割合を引くのは素の最急降下と同じだが、割合は（大域的な）学習率だけでなく、前述の二乗した偏微分の積算和も用いて決める。 その和が大きければ、つまり訓練中の勾配が大きければ大きいほど、調整は小さくなる。1\n\\[\nx_i^{(k+1)} = x_i^{(k)} - \\frac{lr}{\\epsilon + \\sqrt{s_i^{(k)}}}g_i^{(k)}\n\\tag{8.4}\\]\nこの手法の全体的な効果は、パラメタの勾配が一貫して大きいと影響は抑制される。 ずっと勾配が小さいパラメタが変化すると、十分に考慮される。 このアルゴリズムでは、大域的な学習率\\(lr\\)の重要性は低い。 現在の例で最もよい結果に対して、非常に大きな学習率3.7を使える（使う必要がある）。 今回も素の勾配降下（灰の曲線）と比較した結果をFigure 8.2に示す。\n\n\n\n\n\n\nFigure 8.2: Adagrad（白）と素のSGD（灰）との比較\n\n\n\nこの例では、Adagradは非常によい性能を示す。 でもニューラルネットワークの訓練では反復をたくさん行う。 その場合、勾配が積算されていくので、実質的な学習率は次第に減少し、行き止まりに達する。\n他の方法で学習率を個別、パラメタ毎にできないだろうか。\n\n\n8.3.5 RMSProp\nRMSPropはAdagradの積算勾配の方法を重み付き平均に置き換える。 各点で、「簿記」されたパラメタ毎の変数\\(s_i\\)は前の値と前の（二乗）勾配の加重平均とする。\n\\[\ns_i^{(k+1)} = \\gamma s_i^{(k)} + (1 - \\gamma) (g_i^{(k)})^2\n\\tag{8.5}\\]\n更新はAdagradと同様にする。\n\\[\nx_i^{(k+1)} = x_i^{(k)} - \\frac{lr}{\\epsilon + \\sqrt{s_i^{(k)}}}g_i^{(k)}\n\\tag{8.6}\\]\nこの方法では、各パラメタは適切な重みが得られ、全体として学習が遅くなることがない。\n基準であるSGDとの比較を示すFigure 8.3。\n\n\n\n\n\n\nFigure 8.3: RMSProp（白）と素のSGDとの比較\n\n\n\n現時点で、RMSPropは次に述べるAdamに次いで深層学習で最もよく使わている手法である。\n\n\n8.3.6 Adam\nAdamはこれまでに見た二つの概念を組み合わせている。 慣性で「軌道」に留まり、パラメタ依存の更新で速く変化するパラメタへの過剰な依存を回避している。 Adamの手順は次の通りである。2\nまず、慣性付SGDのように、勾配の指数函数的加重平均を維持する。 ここでは加重係数\\(\\gamma_v\\)は通常0.9に設定される。\n\\[\nv_i^{(k+1)} = \\gamma_vv_i^{(k)} + (1 - \\gamma_v)g_i^{(k)}\n\\tag{8.7}\\]\nまた、RSMPropのように二乗勾配の指数函数的加重平均を求め、加重係数\\(\\gamma_s\\)は通常0.999を使う。 \\[\ns_i^{(k+1)} = \\gamma_ss_i^{(k)} + (1 - \\gamma_s)(g_i^{(k)})^2\n\\tag{8.8}\\]\n\\[\nx_i^{(k+1)} = x_i^{(k)} - \\frac{lrv_i^{(k+1)}}{\\epsilon + \\sqrt{s_i^{(k+1)}}}g_i^{(k)}\n\\tag{8.9}\\]\nこの章の締めくくりに、Adamを同じ例で試してみるFigure 8.4。\n\n\n\n\n\n\nFigure 8.4: Adam（白）と素のSGD（灰）\n\n\n\n次の章で扱う損失函数は、取り上げる最後の構成要素で、回帰ネットワークと最小化の例を書き直し、torchのモジュールと最適化器の恩恵を受ける。",
    "crumbs": [
      "torchに慣れる",
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>最適化器</span>"
    ]
  },
  {
    "objectID": "optimizers.html#footnotes",
    "href": "optimizers.html#footnotes",
    "title": "8  最適化器",
    "section": "",
    "text": "ここで\\(\\epsilon\\)は小さな値で0で割ることを防止する。↩︎\n実装は通常追加の手順があるが、ここではその詳細は必要ない。↩︎",
    "crumbs": [
      "torchに慣れる",
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>最適化器</span>"
    ]
  },
  {
    "objectID": "loss-functions.html",
    "href": "loss-functions.html",
    "title": "9  損失函数",
    "section": "",
    "text": "9.1 torchの損失函数\ntorchでは、損失函数はnn_またはnnf_で始まる。\nnnf_を使う場合、直接函数呼び出しを行う。 これに対応して、その（推定と目的の）引数はどちらもテンソルだ。 例えば、nnf_mse_loss()という組込函数は手作業でコードを書いたものに類似している。\nlibrary(torch)\nnnf_mse_loss(torch_ones(2, 2), torch_zeros(2, 2) + 0.1)\n\ntorch_tensor\n0.81\n[ CPUFloatType{} ]\n一方nn_では、まずオブジェクトを作成する。\nl &lt;- nn_mse_loss()\nこのオブジェクトはテンソルに対して呼び出すと、求める損失が得られる。\nl(torch_ones(2, 2), torch_zeros(2, 2) + 0.1)\n\ntorch_tensor\n0.81\n[ CPUFloatType{} ]\nオブジェクトまたは函数のどちらを選択するかは、主に好みと文脈次第だ。 大きなモデルでは、いくつかの損失函数を合わせてつかうことになる。 その際、損失オブジェクトを作る方が部品として扱いやすく、維持しやすいコードになる。 本書では、最初の方法を主に用いるが、特別な理由があれば別の方法を取ることにする。",
    "crumbs": [
      "torchに慣れる",
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>損失函数</span>"
    ]
  },
  {
    "objectID": "loss-functions.html#どの損失函数を選択すべきか",
    "href": "loss-functions.html#どの損失函数を選択すべきか",
    "title": "9  損失函数",
    "section": "9.2 どの損失函数を選択すべきか。",
    "text": "9.2 どの損失函数を選択すべきか。\n深層学習や機械学習全般では、ほとんどの応用は数値の予測または確率の推定のどちらか一つ、または両方を行う。 現在の例の回帰問題は前者を行なっている。 実際の応用では、気温や従業員の離職率を推定したり、売り上げを予測したりする。 後者では、典型的な問題は分類だ。 例えば画像を最も顕著な内容に基づいて分類するには、実際にはそれぞれの確率を計算する。 そして「犬」の確率が0.7で、猫の確率が0.3なら犬と判定する。\n\n9.2.1 最尤法\n分類も回帰も最も使われている損失函数は最尤原理に基づいている。 最尤とは、モデルのパラメタの選択がデータ、つまり観測したものや観測できたかもしれないことが最大限起こりやすいようにする。 この原理は基本的である「だけ」でなく、直感に訴えるものだ。 簡単な例を考えよう。\n例えば、7.1, 22.14, 11.3という値があり、生じさせる過程が正規分布に則っているものとする。 その場合、これらのデータは平均14、標準偏差7の分布により生じたものである可能性が、平均20、標準偏差 1よりもはるかに可能性が高い。\n\n\n9.2.2 回帰\n回帰（目的の分布が正規分布であるという暗黙の仮定をおいたもの^1）では、尤度を最大化するには、これまで計算してきた損失である、平均二乗誤差を引き続き用いればよい。 最尤推定値は望まれる全ての統計的な性質を持つ。 しかしながら、特定の用途では他の損失を使う理由があるかもしれない。 ^1: 仮定があり得ない場合、分布適合損失函数が提供されている（例: Poisson負対数は`nnf_poisson_nll_loss()）。\n例えば、データセットに外れ値があり、何らかの理由で予測と目的がかなりずれていることがある。 平均二乗誤差は外れ値に大きな重みを置く。 そのような場合、代替となりうるのは平均絶対誤差（nnf_l1_loss()）と滑らかなL1損失（`nn_smooth_l1_loss()）である。 後者は混合した型で、既定では絶対（L1）誤差を計算するが二乗（L2）に絶対誤差が非常に小さいところで切り替える。",
    "crumbs": [
      "torchに慣れる",
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>損失函数</span>"
    ]
  },
  {
    "objectID": "references.html",
    "href": "references.html",
    "title": "参考文献",
    "section": "",
    "text": "Bronstein, Michael M., Joan Bruna, Taco Cohen, and Petar Velickovic.\n2021. “Geometric Deep Learning: Grids, Groups, Graphs, Geodesics,\nand Gauges.” CoRR abs/2104.13478. https://arxiv.org/abs/2104.13478.",
    "crumbs": [
      "参考文献"
    ]
  }
]