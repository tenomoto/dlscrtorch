# データの読み込み

おもちゃの例については、第三版（最終版）を次の章で見るが、小さなデータの集合に対して訓練した。
あまりに小さいので、全ての観測を一挙にモデルに対して学習できる。
そうでない場合はどうなるのか。
例えば、10,000要素あり、各要素が256 x 256画素のRGB画像だったとしたら。
非常に強力な装置でも、モデルの訓練を一度に全てのデータに対して行うことはおそらくできないだろう。

その理由から、`torch` のようなフレームワークは入力パイプラインが含まれており、データをモデルに *バッチ* つまり観測の一部 を渡せるようになっている。
この過程に関わるのは、二つのクラス `dataset()` と `dataloader()` だ。
こられのインスタンスの作り方を見る前に、それらの目的に応じた特徴づけをしておこう。

## データと `dataset()` と`dataloader()` の違い

本書では、「データセット」（可変幅フォント、括弧なし）あるいは単に「データ」は、通常Rの行列、`data.frame`やそれらに含まれるものを指す。
`dataset()` （固定幅フォント、括弧つき）は、`torch` のオブジェクトでできることが一つある。
それは、呼び出し相手に対して単一の項目を渡すことだ。
その項目は通常リストで、一つの入力と一つの目的テンソルから構成されている。
（実は課題に対して意味をなすものであればなんでもよい。例えば、単一のテンソルで入力と出力を兼ねることもありうる。二つ以上のテンソルが異なる入力として異なるモジュールに渡されることも考えられる。）

上述の目的を満たす限り、`dataset()` は必要なことを自由にできる。
例えば、データをインターネットからダウンロードし一時的な場所に保存したり、何んらかの前処理をしたり、
ある種類のモデルに必要とされるデータのバイト単位の塊を返したりすることもある。
裏で何をしようとも、呼び出しの相手が求めるのは単一の項目を返すことだ。
呼び出すのは、`dataloader()` である。

`dataloader()` の役割は、モデルにバッチで入力することだ。
一つの直接的な理由は、コンピュータのメモリだ。
多くの `dataset()` は一度にモデルに渡すには大きすぎる。
他にもバッチにする利点がある。
勾配の計算（そしてモデルの重みの更新）をバッチ毎に行うと、過程に対する固有の確率的な性質があり、これがモデルの訓練に役立つ。
これは、後の章で詳しく議論する。

## `dataset()` の使い方

`dataset()` には様々なものがある。
`torchvision`  や `torchdatasets` 、その他`torch` で使えるように準備済のデータを提供しているパッケージに含まれ、すぐに使えるようになっているものから、完全に変更できる（つまりユーザ自身による準備が必要な）ものまである。
`dataset()` を作るのは簡単だ。
これらはR6オブジェクトで、実装が必要なメソッドは次の三つだけだ。

1. `initialize(...)`。 `initialize()`に渡すパラメタは、`dataset()`のインスタンスが作られた時に渡される。
考えられるのは、Rの `data.frame` やファイルシステムのパス、ダウンロードのURL、`dataset()` が期待する様々な設定やパラメタがあるが、それらに限定されない。

2. `.getitem(i)`。これは契約を満たすことを担うメソッドである。
返すものは全て単一の要素である。
パラメタ `i` は、多くの場合、背景のデータ構造（例えば、ファイルシステムのパスの `data.frame`） における開始位置を示すインデックスである。
でも、 `dataset()` は、このパラメタを使わなければならないわけではない。
例えば、非常に巨大な `dataset()` や、クラスにかなりの不均衡がある場合、代わりに標本抽出に基づいた要素を返すこともできる。

3. `.length()` 通常これは一行で、唯一の目的は `dataset()` で利用できる要素の数を返すことだ。

`dataset()` の青写真を示す。

```r
ds <- dataset()(
  initialize = function(...) {
    ...
  },
  .getitem = function(index) {
    ...
  },
  .length = function() {
    ...
  }
)
```

ということで、作業に用いる `dataset()` を得る三つの方法について、注文仕立てから、最も楽なものまで、比較してみよう。

### 自作 `dataset()`

`iris` の代替である `palmerpenguins` に基づく判別器を構築したいとする。

```{r}
library(torch)
library(palmerpenguins)

str(penguins)
```

`species` の予測において `bill_length_mm` と `bill_depth_mm` 、 `flipper_length_mm` 、 `body_mass_g` の一部を用いる。
必要なものをちょうど返す `dataset()` を作る。

```{r}
penguins_dataset <- dataset(
  name = "penguins_dataset",
  initialize = function(df) {
    df <- na.omit(df)
    self$x <- as.matrix(df[, 3:6]) |> torch_tensor()
    self$y <- torch_tensor(
      as.numeric(df$species)
    )$to(torch_long())
  },
  .getitem = function(i) {
    list(x = self$x[i, ], y = self$y[i])
  },
  .length = function() {
    dim(self$x)[1]
  }
)
```

一度 `penguins_dataset` のインスタンスを作成したら、すぐに簡単な確認をしよう。
まず、期待される長さから。

```{r}
ds <- penguins_dataset(penguins)
length(ds)
```

次に、ここの要素は期待通りの形状とデータ型であるか。
インデックスを使って、`dataset()` の要素にテンソルの値のように表示できるのは便利だ。

```{r}
ds[1]
```

これは `dataset()` を掘り下げて行ったときにも動作するし、しなければならない。
`dataset()` のインデックスは、裏では 求める位置 `i` で `.getitem()` を呼び出す。

実際には、自作の `dataset()` を作成しなかった。
ほとんど前処理が不要な、代替となる `tensor_dataset()` がある。

### `tensor_dataset()`
  
テンソルが既にあるときや、容易に変換できるときは、組込の `dataset()` ジェネレータ である `tensor_dataset()` を使うことができる。
この函数は任意の数のテンソルを受け取ることができる。
個々のバッチ要素は、テンソル値のリストである。

```{r}
three <- tensor_dataset(
  torch_randn(10), torch_randn(10), torch_randn(10)
)
three[1]
```

`penguins` の文脈では、二行のコードになる。

```{r}
penguies <- na.omit(penguins)
ds <- tensor_dataset(
  torch_tensor(as.matrix(penguins[, 3:6])),
  torch_tensor(
    as.numeric(penguins$species)
  )$to(torch_long())
)

ds[1]
```

しかしながら、データセットの全ての列を使っていないことは認めざるを得ない。
より多く前処理を `dataset()` に行わせるには、より多くのコードを書く必要がある。

三番目かつ、最後に最も楽な方法を示す。

### `torchvision::mnist_dataset()`

`torch` のエコシステムにおけるパッケージを使っているとき、実例かデータ自体が目的かは別として、何らかの `dataset()` を含んでいる可能性が高い。
`torchvision` は、古典的な画像のデータセットを提供している。
その中で、典型中の典型が MNIST である。

後の章で画像処理を議論するので、 `minst_dataset()` の引数についてここで述べることにする。
ここでは、データが期待されるものに適合しているか簡単に確認する。

```{r}

library(torchvision)

dir <- "~/.torch-datasets"

ds <- mnist_dataset(
  root = dir,
  train = TRUE, # 既定
  download = TRUE,
  transform = function(x) {
    x |> transform_to_tensor()
  }
)

first <- ds[1]
cat("Image shape: ", first$x$shape, " Label: ", first$y, "\n")
```

この時点では、`dateset()` について知っておくことは全てだ。
本書を読み進める中で多く出会うことになる。
それでは、単一から複数のデータに進もう。

## `dataloader()` の使い方

新たに作成したMNISTの `dataset()` を使って、これに対する `dataloader()` のインスタンスを作成する。
`dataloader()` は、一度に32個のバッチにおいて画像とラベルの組みを返す。
各エポックで、異なる順序で返す（`shuffle = TRUE`）。

```{r}
dl <- dataloader(ds, batch_size = 32, shuffle = TRUE)
```

`dataset()` 同様に `dataloader()` も長さを確認できる。

```{r}
length(dl)
```

今回は、返り値は要素の数ではなく、バッチの数である。

バッチに亙り繰り返すには、先にイテレータを得る。
このオブジェクトは、この `dataloader()` の要素を辿りかたを知っている。
`datalader_next()` を呼び足すと、一つずつ次のバッチを得ることができる。

```{r}
first_batch <- dl |>
  # この dataloader に対するイテレータを得る。
  dataloader_make_iter() |>
  dataloader_next()

dim(first_batch$x)
dim(first_batch$y)
```

`x` の形状、画像部分と個々の（上で確認した）画像、今追加された次元が、バッチにある画像の数を反映していることが分かる。

次の段階は、バッチをモデルに与えることである。
実は、これと完全な、端から端までの深層学習の手順は次の章で扱う内容である。
